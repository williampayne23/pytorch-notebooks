{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156cfb0c",
   "metadata": {
    "id": "79b1d3c2-9285-4496-9190-0d29ad49cae1",
    "tags": []
   },
   "source": [
    "# Transformer\n",
    "Working from [this](https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc3551",
   "metadata": {
    "id": "d850b9a1-b6ce-4ab4-866e-a6e0bd092ca3"
   },
   "source": [
    "## Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00039c",
   "metadata": {
    "id": "2bf8b945-0591-4553-908a-ecce6b7f6f93"
   },
   "source": [
    "1. What is different architecturally from the Transformer, vs a normal RNN, like an LSTM? (Specifically, how are recurrence and time managed?)\n",
    "    \n",
    "    No recurrance, time uses positional embeddings, self attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec38f12",
   "metadata": {
    "id": "662a0412-3d60-4786-9cee-cce82598fd13"
   },
   "source": [
    "2. Attention is defined as, $\\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$. What are the dimensions for Q, K, and V? Why do we use this setup? What other combinations could we do with (Q,K) that also output weights?\n",
    "\n",
    "  $\\text{seq_length} \\times d_k, d_k, d_v$\n",
    "\n",
    "  So $QK^T$ is a $(\\text{seq_length}, \\text{seq_length})$ matrix and Attention is a $(\\text{seq_length}, d_v)$ matrix\n",
    "  \n",
    "  But MultiHead attention is defined as\n",
    "  \n",
    "  $\\text{MultiHeadAttention}(Q, K, V) = \\text{concat}(\\text{head}_1, \\text{head}_2, \\ldots)W_0$\n",
    "  \n",
    "  These heads are defined as\n",
    "  \n",
    "  $\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^Q)$\n",
    "  \n",
    "  Where\n",
    "  \n",
    "  $W_i^Q \\in \\mathbb{R}^{d_\\text{model}\\times d_k}, W_i^K \\in \\mathbb{R}^{d_\\text{model}\\times d_k} , W_i^V \\in \\mathbb{R}^{d_\\text{model}\\times d_v}$ and $W_O \\in \\mathbb{R}^{hd_v\\times d_\\text{model}}$.\n",
    "  \n",
    "  This means working backward that for multi headed attention\n",
    "  \n",
    "  $Q, K, \\text{and } V \\in \\mathbb{R}^{\\text{seq_length} \\times d_\\text{model}}$\n",
    "  \n",
    "  and\n",
    "  \n",
    "  $\\text{concat}(\\text{head}_1, \\text{head}_2, \\ldots) \\in \\mathbb{R}^{\\text{seq_length} \\times hd_\\text{dv}}$ \n",
    "  \n",
    "  so\n",
    "  \n",
    "  $\\text{MultiHeadAttention}(Q, K, V) \\in \\mathbb{R}^{\\text{seq_length} \\times d_\\text{model}}$\n",
    "  \n",
    "  It seems like in a lot of implementations there is just one W^Q matrix which is all the W_i^Q matrices concatinated together so $W^Q \\in \\mathbb{R}^{d_\\text{model} \\times hd_k}$ which means $W^Q \\in \\mathbb{R}^{d_\\text{model} \\times d_\\text{model}}$\n",
    "  \n",
    "  You then have to split it up again for the Attention function (since the creation of self attn (softmax($QK^T$)) is the part that we get independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66d59c",
   "metadata": {
    "id": "421bc392-3901-44e6-ac28-92475cf4fa39"
   },
   "source": [
    "3. Are the dense layers different at each multi-head attention block? Why or why not?\n",
    "\n",
    "    Yes, so the different blocks can encode different relationships / focusses in attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461e17e",
   "metadata": {
    "id": "59fa34d6-5370-441a-8109-b1cbe4fb7f3d"
   },
   "source": [
    "4. Why do we have so many skip connections, especially connecting the input of an attention function to the output? Intuitively, what if we didn't?\n",
    "    The original word embedding might get buried under noise if it isn't reinforced. \n",
    "    \n",
    "    From solution:\n",
    "        In the ResNet paper, it was observed that some deep neural networks perform worse than their shallow counterparts. Adding skip connections empirically seemed to solve this issue. The intuition is that adding skip connections allows layers to learn the identity mapping more easily. \"To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers.\"\n",
    "\n",
    "    If we didn't include these skip connections, we might experience a degradation of performance for very deep transformer models due to vanishing / exploding gradient problems.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f473b5",
   "metadata": {
    "id": "70f372c8-d50e-4e14-b4b1-46b00626d5e7"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ed375c",
   "metadata": {
    "id": "f758f849-84f1-47c7-bfa3-6669f63b9b18"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math, copy\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fe583",
   "metadata": {
    "id": "af717fa2-cb60-4090-8c99-686204732e60",
    "tags": []
   },
   "source": [
    "### Implement the positional embeddings function first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9646481",
   "metadata": {
    "id": "6a9035b4-953b-4053-aa69-19ed79c9ded2"
   },
   "source": [
    "Equations\n",
    "\n",
    "$PE(pos,2i) = \\sin(pos/10000^{2i/d_{model}})$\n",
    "\n",
    "$PE(pos,2i + 1) = \\cos(pos/10000^{2i/d_{model}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56473cef",
   "metadata": {
    "id": "1cb4ccc5-457e-4d12-8bc4-771059ac10f1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        torch.zeros(d_model)\n",
    "        \n",
    "        encodings = torch.zeros(max_len, d_model)\n",
    "        dimensions = torch.arange(d_model)\n",
    "        denominator = div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        positions = torch.arange(max_len).unsqueeze(1)\n",
    "        encodings[:,0::2] = torch.sin(positions * denominator)\n",
    "        encodings[:,1::2] = torch.cos(positions * denominator)\n",
    "        self.register_buffer('encodings', encodings) #Registers a persistent buffer for this layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x; batch_size, seq_length, d_model\n",
    "        x = x + self.encodings[:x.size(-2)]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a337ec4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "b9346a52-3aac-43ef-b7b6-c985f705536a",
    "outputId": "14422838-c0d9-460b-ba8f-f38d842fbca5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe = PositionalEmbedding(100, 0)\n",
    "y = pe.forward(torch.zeros(2, 100, 100))\n",
    "plt.imshow(y[0], cmap='Blues', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a711898",
   "metadata": {
    "id": "183cb078-d69c-47bf-8fe3-a06f1e7f80e1"
   },
   "source": [
    "### Then implement the function which calculates attention, given (Q,K,V) as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6a0031",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a721a71-98dc-41bd-a903-c0558803759a",
    "outputId": "b6b23140-a701-4f77-e151-8da04ea31644"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[4,5,6]]).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba114fec",
   "metadata": {
    "id": "a9411fb5-7b8b-424e-a4e5-c96dadf1180e"
   },
   "outputs": [],
   "source": [
    "def attention(Q, K, V, mask=None, dropout=None):\n",
    "    #Q, K, V; batch_size, h, seq_length, dk or dv\n",
    "    rt_d_k = math.sqrt(Q.size(-1))\n",
    "    scores = torch.matmul(Q, K.transpose(-1,-2)) / rt_d_k\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -math.inf)\n",
    "        \n",
    "    p_att = scores.softmax(dim=-1)\n",
    "    size = V.size()\n",
    "    if dropout is not None:\n",
    "        p_att = dropout(p_att)\n",
    "    \n",
    "    return torch.matmul(p_att, V), p_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a8904",
   "metadata": {
    "id": "00d08431-3c7f-426e-ab9c-dc0fa1eb0ff8"
   },
   "source": [
    "### Now implement the masking function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13900a5",
   "metadata": {
    "id": "bf0b6051-c94e-4dd6-aa24-c4938feb7d69"
   },
   "outputs": [],
   "source": [
    "def masked_attention(Q, K, V):\n",
    "    print(mask)\n",
    "    return attention(Q, K, V, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12309e30",
   "metadata": {
    "id": "aea2fb2e-ea5f-418f-93f2-d1a01b76d5d4"
   },
   "source": [
    "### Put it all together to form an entire attention block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c747f3f",
   "metadata": {
    "id": "c8691388-400d-4a65-b469-d7cb883880b1"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, h = 8, mask=None):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.h = h\n",
    "        self.dk = d_model // h\n",
    "        self.dv = self.dk\n",
    "        self.attn = None\n",
    "        self.mask = mask\n",
    "        self.WQ = nn.Linear(d_model, d_model)\n",
    "        self.WK = nn.Linear(d_model, d_model)\n",
    "        self.WV = nn.Linear(d_model, d_model)\n",
    "        self.W0 = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # x; batch_size, seq_length, d_model\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        #Linearly project X into Q, K, and V\n",
    "        queries = self.WQ(x) #batch_size, seq_length, d_model\n",
    "        keys = self.WK(x)    #batch_size, seq_length, d_model\n",
    "        values = self.WV(x)  #batch_size, seq_length, d_model\n",
    "        \n",
    "        #Split Q, K, and V into multi headed\n",
    "        queries = queries.view(batch_size, -1, self.h, self.dk).transpose(1,2)\n",
    "        keys = keys.view(batch_size, -1, self.h, self.dk).transpose(1,2)\n",
    "        values = values.view(batch_size, -1, self.h, self.dv).transpose(1,2)\n",
    "        \n",
    "        #q,k,v ; batch_size, h, seq_length, (dk or dv)\n",
    "        \n",
    "        x, self.attn = attention(queries, keys, values, mask, self.dropout)\n",
    "        #x; batch_size, h, seq_length, dk\n",
    "        #self.attn; batch_size, \n",
    "        \n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.dk * self.h)\n",
    "        #x; batch_size, seq_length, model_size\n",
    "        \n",
    "        return self.W0(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b47dd2",
   "metadata": {
    "id": "03141d67-cadc-4cce-a033-ed3cc93d44ca"
   },
   "source": [
    "### Finish the whole architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71883c64",
   "metadata": {
    "id": "35e31cef-9f1a-4c22-a449-ab070cc5ce04",
    "tags": []
   },
   "source": [
    "#### Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fd8d00",
   "metadata": {
    "id": "4bea66c8-645d-4ec1-a97e-11f8fd3af95b"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.seq = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                 nn.ReLU(), \n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(d_ff, d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0dee2af",
   "metadata": {
    "id": "5a6c0842-6839-4428-82b3-acbeb120e32c"
   },
   "outputs": [],
   "source": [
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(AddAndNorm, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "    \n",
    "    def forward(self, x, layer):\n",
    "        return self.norm(x + layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e27755f",
   "metadata": {
    "id": "582e3e7c-bfce-44dc-9072-f2099671dea7"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, hidden_layers=2048, dropout=0.1, h=8):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mha = MultiHeadedAttention(d_model, dropout, h)\n",
    "        self.ffn = FeedForwardNetwork(d_model, hidden_layers, dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        base_mask = torch.tril(torch.ones(x.size(-2), x.size(-2))).to(x.device)\n",
    "        if mask is not None:\n",
    "            base_mask = mask*base_mask\n",
    "        x = self.ln1(x + self.mha(x, base_mask))\n",
    "        x = self.ln2(x + self.ffn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0475a26",
   "metadata": {
    "id": "a91c6050-1d12-4349-8f6f-ef670fd045b5"
   },
   "source": [
    "#### Decoder Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c714e6d9",
   "metadata": {
    "id": "6791f031-2b1a-4369-9bd5-61874187170c"
   },
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, d_model, N=8, hidden_layers=2048, dropout=0.1, h=8):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.decoder_blocks = nn.ModuleList([copy.deepcopy(DecoderBlock(d_model, hidden_layers, dropout, h)) for x in range(N)])\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3748c2",
   "metadata": {
    "id": "dee69bf4-909d-4536-9dea-48b482396448"
   },
   "source": [
    "#### Decoder only transformer\n",
    "Learned Embeddings -> +Positional embeddings -> Decoder Block (*N) -> Linear -> Softmax -> Output probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24626c05",
   "metadata": {
    "id": "8af8f781-52c2-4bbc-bf8f-2d48773ace7f"
   },
   "outputs": [],
   "source": [
    "class DecoderTransformer(nn.Module):\n",
    "    def __init__(self, d_model, vocab, N=8, ffl=2048, dropout=0.1, h=8):\n",
    "        super(DecoderTransformer, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.learned_embeddings = nn.Embedding(vocab, d_model)\n",
    "        self.positional_embedding = PositionalEmbedding(d_model, dropout=dropout)\n",
    "        self.decoder_stack = DecoderStack(d_model, N=N, hidden_layers=ffl, dropout=dropout, h=h)\n",
    "        self.lin = nn.Linear(d_model, vocab)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        #x; batch_size, seq_length, vocab_len\n",
    "        embedding = self.learned_embeddings(x) #batch_size, seq_length, d_model\n",
    "        pos_embedding = self.positional_embedding(embedding) #batch_size, seq_length, d_model\n",
    "        final_embedding = self.decoder_stack(pos_embedding) #batch_size, seq_length, d_model\n",
    "        logits = self.lin(final_embedding) #.softmax(dim=-1) #batch_size, seq_length, vocab_len\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17367267",
   "metadata": {
    "id": "6f75dfca-4c85-4ad9-8a3e-5db00aae0eb5"
   },
   "source": [
    "### Training on the reverse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4ed787",
   "metadata": {
    "id": "657a5b85-945d-435c-9fc4-9c29532fbb4f"
   },
   "outputs": [],
   "source": [
    "class ReverseDataset(Dataset):\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.size = 10**length # total number of possible combinations\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.randint(10, size=(self.length,), dtype=torch.long)\n",
    "        y = torch.flip(x,(-1,))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e171e8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e0ba522-b5b9-4714-877a-edb55a11db7f",
    "outputId": "dd0814b2-0123-407c-c34f-854d4f9e7ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "rd = ReverseDataset(6)\n",
    "\n",
    "batch_size = 2048\n",
    "train_loader = DataLoader(\n",
    "    rd, shuffle=True, pin_memory=True, batch_size=batch_size\n",
    ")\n",
    "device =torch.device(\"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cce4a8",
   "metadata": {
    "id": "oEYjlRJT2c7-"
   },
   "source": [
    "#### Functional optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c60bcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "7d2e5765-8363-4e46-8f88-1d8f12bf54d8",
    "outputId": "cb42c59a-5962-498d-ea60-e86ce63e6d90"
   },
   "outputs": [],
   "source": [
    "model = DecoderTransformer(\n",
    "  d_model=128, \n",
    "  vocab=10, \n",
    "  N=2,\n",
    "  ffl=512, \n",
    "  dropout=0.1, \n",
    "  h=4\n",
    ").to(device).train()\n",
    "\n",
    "def train(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    max_epochs = 1\n",
    "    losses = [];\n",
    "    for epoch in range(max_epochs):\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for it, (x, y) in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            loss.backward()\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "            optimizer.step()\n",
    "            pbar.set_description(f\"epoch {epoch} iter {it}: train loss {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "402ecc29-caa3-41e8-b916-4e955a625db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5a608",
   "metadata": {
    "id": "2bRzO4nu2yVW"
   },
   "source": [
    "#### Wrapper optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b87ef21",
   "metadata": {
    "id": "Stsh_1jbmOlx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTransformerWrapper():\n",
    "    def __init__(self, model):\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.decoder_transformer = model.to(self.device)\n",
    "        self.losses = []\n",
    "\n",
    "    @classmethod\n",
    "    def from_parameters(cls, d_model, vocab, ffl_s=None, height=4, heads=8, dropout=0.1):\n",
    "        #vocab should be a list of allowed values\n",
    "        if ffl_s is None:\n",
    "            ffl_s = d_model * 4\n",
    "        model = DecoderTransformer(\n",
    "          d_model=d_model, \n",
    "          vocab=len(vocab), \n",
    "          N=height,\n",
    "          ffl=ffl_s, \n",
    "          dropout=dropout, \n",
    "          h=heads\n",
    "        )\n",
    "        return cls(model)\n",
    "\n",
    "    def train(self, train_loader, lr=1e-4, max_epochs=1, loss_fn=nn.CrossEntropyLoss(), test_lambda=None):\n",
    "        self.decoder_transformer.train()\n",
    "        optimizer = optim.Adam(self.decoder_transformer.parameters(), lr=lr)\n",
    "        self.losses = []\n",
    "        for epoch in range(max_epochs):\n",
    "            pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "            for it, (x, y) in pbar:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                logits = self.decoder_transformer(x)\n",
    "                loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                loss.backward()\n",
    "                self.losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                if test_lambda is None:\n",
    "                    correct = (pred == y).type(torch.float).sum().item()\n",
    "                else:\n",
    "                    correct = test_lambda(pred, y).type(torch.float).sum().item()\n",
    "                accuracy = correct / x.size(0)\n",
    "                optimizer.step()\n",
    "                pbar.set_description(f\"epoch {epoch} iter {it}: train loss {loss.item():.5f}, accuracy {accuracy*100:0.2f}%\")\n",
    "  \n",
    "    def test(self, test_loader, test_lambda=None):\n",
    "        self.decoder_transformer.eval()\n",
    "        correct = 0\n",
    "        n = 0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "            for it, (x, y) in pbar:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                n += x.size(0)\n",
    "                logits = self.decoder_transformer(x)\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                if test_lambda is None:\n",
    "                    correct += (pred == y).type(torch.float).sum().item()\n",
    "                else:\n",
    "                    correct += test_lambda(pred, y).type(torch.float).sum().item()\n",
    "                accuracy = correct / n\n",
    "                pbar.set_description(f\"iter {it}: test accuracy {accuracy*100:.2f}%\")    \n",
    "    def eval(self, x):\n",
    "        self.decoder_transformer.eval()\n",
    "        x = x.to(self.device)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logits = self.decoder_transformer(x)\n",
    "        return logits.argmax(dim=-1)\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        self.decoder_transformer.to(device)\n",
    "\n",
    "\n",
    "if 'handler' in locals():\n",
    "    handler = DecoderTransformerWrapper(handler.decoder_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad85f51",
   "metadata": {
    "id": "Zff1BZA2oViu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 488: train loss 1.22697, accuracy 89.93%: 100%|| 489/489 [02:50<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = DecoderTransformerWrapper.from_parameters(d_model=128,\n",
    "                                    vocab=range(10),\n",
    "                                    height=2,\n",
    "                                    ffl_s=512, \n",
    "                                    dropout=0.1, \n",
    "                                    heads=4)\n",
    "handler.to(torch.device('cpu'))\n",
    "handler.train(train_loader, test_lambda=lambda pred, y: (pred == y)[:, -3:].all(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f497076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T17:03:25.646316Z",
     "iopub.status.busy": "2022-10-17T17:03:25.645955Z",
     "iopub.status.idle": "2022-10-17T17:03:40.556363Z",
     "shell.execute_reply": "2022-10-17T17:03:40.555249Z",
     "shell.execute_reply.started": "2022-10-17T17:03:25.646285Z"
    },
    "id": "H8dKrAFQtKLF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter 399: test accuracy 100.00%:  41%|      | 400/977 [00:22<00:32, 17.92it/s]\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      2\u001b[0m     rd, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 58\u001b[0m, in \u001b[0;36mDecoderTransformerWrapper.test\u001b[0;34m(self, test_loader, test_lambda)\u001b[0m\n\u001b[1;32m     56\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     57\u001b[0m n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m pred \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_lambda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1357\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1355\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1356\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1357\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [12], line 15\u001b[0m, in \u001b[0;36mDecoderTransformer.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearned_embeddings(x) \u001b[38;5;66;03m#batch_size, seq_length, d_model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m pos_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding(embedding) \u001b[38;5;66;03m#batch_size, seq_length, d_model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m final_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_embedding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#batch_size, seq_length, d_model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(final_embedding) \u001b[38;5;66;03m#.softmax(dim=-1) #batch_size, seq_length, vocab_len\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1357\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1355\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1356\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1357\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [11], line 8\u001b[0m, in \u001b[0;36mDecoderStack.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_blocks:\n\u001b[0;32m----> 8\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1357\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1355\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1356\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1357\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [10], line 14\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     base_mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m*\u001b[39mbase_mask\n\u001b[0;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1357\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1355\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1356\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1357\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [7], line 32\u001b[0m, in \u001b[0;36mMultiHeadedAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdv)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#q,k,v ; batch_size, h, seq_length, (dk or dv)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#x; batch_size, h, seq_length, dk\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#self.attn; batch_size, \u001b[39;00m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdk \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh)\n",
      "Cell \u001b[0;32mIn [5], line 8\u001b[0m, in \u001b[0;36mattention\u001b[0;34m(Q, K, V, mask, dropout)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m----> 8\u001b[0m p_att \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m size \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "    rd, shuffle=True, pin_memory=True, batch_size=1024\n",
    ")\n",
    "handler.test(test_loader, test_lambda=lambda pred, y: (pred == y)[:, -3:].all(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d506cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a955a5d6d72dcc9422ec8add5a84d6ce2101e50b4aaf9a0a8386fcbc86cc6bec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
