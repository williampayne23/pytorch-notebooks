{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ec16d0-b3d2-439a-8a6b-9e6e2214f0d0",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=https://colab.research.google.com/github/williampayne23/pytorch-notebooks/blob/main/Transformer.ipynb target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156cfb0c",
   "metadata": {
    "id": "79b1d3c2-9285-4496-9190-0d29ad49cae1",
    "tags": []
   },
   "source": [
    "# Transformer\n",
    "Working from [this](https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc3551",
   "metadata": {
    "id": "d850b9a1-b6ce-4ab4-866e-a6e0bd092ca3"
   },
   "source": [
    "## Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00039c",
   "metadata": {
    "id": "2bf8b945-0591-4553-908a-ecce6b7f6f93"
   },
   "source": [
    "1. What is different architecturally from the Transformer, vs a normal RNN, like an LSTM? (Specifically, how are recurrence and time managed?) \n",
    "    \n",
    "    No recurrance, time uses positional embeddings, self attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec38f12",
   "metadata": {
    "id": "662a0412-3d60-4786-9cee-cce82598fd13"
   },
   "source": [
    "2. Attention is defined as, $\\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$. What are the dimensions for Q, K, and V? Why do we use this setup? What other combinations could we do with (Q,K) that also output weights?\n",
    "\n",
    "  $\\text{seq_length} \\times d_k, d_k, d_v$\n",
    "\n",
    "  So $QK^T$ is a $(\\text{seq_length}, \\text{seq_length})$ matrix and Attention is a $(\\text{seq_length}, d_v)$ matrix\n",
    "  \n",
    "  But MultiHead attention is defined as\n",
    "  \n",
    "  $\\text{MultiHeadAttention}(Q, K, V) = \\text{concat}(\\text{head}_1, \\text{head}_2, \\ldots)W_0$\n",
    "  \n",
    "  These heads are defined as\n",
    "  \n",
    "  $\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^Q)$\n",
    "  \n",
    "  Where\n",
    "  \n",
    "  $W_i^Q \\in \\mathbb{R}^{d_\\text{model}\\times d_k}, W_i^K \\in \\mathbb{R}^{d_\\text{model}\\times d_k} , W_i^V \\in \\mathbb{R}^{d_\\text{model}\\times d_v}$ and $W_O \\in \\mathbb{R}^{hd_v\\times d_\\text{model}}$.\n",
    "  \n",
    "  This means working backward that for multi headed attention\n",
    "  \n",
    "  $Q, K, \\text{and } V \\in \\mathbb{R}^{\\text{seq_length} \\times d_\\text{model}}$\n",
    "  \n",
    "  and\n",
    "  \n",
    "  $\\text{concat}(\\text{head}_1, \\text{head}_2, \\ldots) \\in \\mathbb{R}^{\\text{seq_length} \\times hd_\\text{dv}}$ \n",
    "  \n",
    "  so\n",
    "  \n",
    "  $\\text{MultiHeadAttention}(Q, K, V) \\in \\mathbb{R}^{\\text{seq_length} \\times d_\\text{model}}$\n",
    "  \n",
    "  It seems like in a lot of implementations there is just one W^Q matrix which is all the W_i^Q matrices concatinated together so $W^Q \\in \\mathbb{R}^{d_\\text{model} \\times hd_k}$ which means $W^Q \\in \\mathbb{R}^{d_\\text{model} \\times d_\\text{model}}$\n",
    "  \n",
    "  You then have to split it up again for the Attention function (since the creation of self attn (softmax($QK^T$)) is the part that we get independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66d59c",
   "metadata": {
    "id": "421bc392-3901-44e6-ac28-92475cf4fa39"
   },
   "source": [
    "3. Are the dense layers different at each multi-head attention block? Why or why not?\n",
    "\n",
    "    Yes, so the different blocks can encode different relationships / focusses in attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461e17e",
   "metadata": {
    "id": "59fa34d6-5370-441a-8109-b1cbe4fb7f3d"
   },
   "source": [
    "4. Why do we have so many skip connections, especially connecting the input of an attention function to the output? Intuitively, what if we didn't?\n",
    "    The original word embedding might get buried under noise if it isn't reinforced. \n",
    "    \n",
    "    From solution:\n",
    "        In the ResNet paper, it was observed that some deep neural networks perform worse than their shallow counterparts. Adding skip connections empirically seemed to solve this issue. The intuition is that adding skip connections allows layers to learn the identity mapping more easily. \"To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers.\"\n",
    "\n",
    "    If we didn't include these skip connections, we might experience a degradation of performance for very deep transformer models due to vanishing / exploding gradient problems.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f473b5",
   "metadata": {
    "id": "70f372c8-d50e-4e14-b4b1-46b00626d5e7"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ed375c",
   "metadata": {
    "id": "f758f849-84f1-47c7-bfa3-6669f63b9b18"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math, copy\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fe583",
   "metadata": {
    "id": "af717fa2-cb60-4090-8c99-686204732e60",
    "tags": []
   },
   "source": [
    "### Implement the positional embeddings function first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9646481",
   "metadata": {
    "id": "6a9035b4-953b-4053-aa69-19ed79c9ded2"
   },
   "source": [
    "Equations\n",
    "\n",
    "$PE(pos,2i) = \\sin(pos/10000^{2i/d_{model}})$\n",
    "\n",
    "$PE(pos,2i + 1) = \\cos(pos/10000^{2i/d_{model}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56473cef",
   "metadata": {
    "id": "1cb4ccc5-457e-4d12-8bc4-771059ac10f1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        torch.zeros(d_model)\n",
    "        \n",
    "        encodings = torch.zeros(max_len, d_model)\n",
    "        dimensions = torch.arange(d_model)\n",
    "        denominator = div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        positions = torch.arange(max_len).unsqueeze(1)\n",
    "        encodings[:,0::2] = torch.sin(positions * denominator)\n",
    "        encodings[:,1::2] = torch.cos(positions * denominator)\n",
    "        self.register_buffer('encodings', encodings) #Registers a persistent buffer for this layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x; batch_size, seq_length, d_model\n",
    "        x = x + self.encodings[:x.size(-2)]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a337ec4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "b9346a52-3aac-43ef-b7b6-c985f705536a",
    "outputId": "14422838-c0d9-460b-ba8f-f38d842fbca5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABOyElEQVR4nO29eZxddX3///zMvu+TZLJOSEJCSAhL2EGQvcjihiAWEUW0dQG1Vaqt2tqvlWpb9wVFiv3Zoli24squgAFCgIQkJIEkkz0zk9n3meT8/ni/P2e7987cSSY3y/28Hg8emXPO53POmat3Xu/19Tae5+Hg4HD0I+dQv4CDg0Nm4L7sDg5ZAvdld3DIErgvu4NDlsB92R0csgTuy+7gkCU4oC+7MeYyY8w6Y8wbxpjbJ+qlHBwcJh5mf/PsxphcYD1wMbANeBF4r+d5aybu9RwcHCYKeQew9zTgDc/zNgIYY+4FrgZSftmLK6q98knTaN3RDEDd1En+tfi5sY7Hs2c8983UniP9dz7S3/9o/Z29oW68kX5DEhzIl30asDV0vA04Pb7IGHMLcAtAWV0D1/zrL/npV74PwDX/8Nf+uvi5sY7Hs2c8983UniP9dz7S3/9o/Z0H1/2SVDiQL3ta8DzvTuBOgJyK6d5Pf/AIdWdfLC/38z/76woXngHALx5eKSdmLgLg4Sc2yHHdTAAee35LcPOKegCeXblTjksqAVixoUWOC4r9pau3tMsPeQUAbNjZJce58hE0tfTIcU6uv2dHW5/8YOQPZUvXQOS4rWcw4fft6huOHPcMjESO+wajxwADw3sjx4Mj+yLHw3ujxwAje71RjwH27vNGPU7mwcXPjXXscOTgQAJ024EZoePpes7BweEwxIEw+4vAPGPMbORLfh1w/ag79u2F/i7u+uuzALj6ff/oX/rk1z4JwNc//z0ALvrIXwLw2M8eAmDuW88H4I0XV/l7qo9bLOfWiDeRN+NYAN5cv1sW1Df6azdtapMf1BrYuq1TjtUa2LFbmb2wxN/T3K7Mnl8EQEunMntuPgDtPUN6HHyMHX16Ti2E7n5lerUGesPMruf6h2LMHj8eTmT2ONuP7EvC/jEm3+eNzvTJzsX3xI9h/6wBZyFkHvv9Zfc8b8QY83Hg90Au8FPP81ZP2Js5ODhMKA7IZ/c87zfAbyboXRwcHA4iDnqALozKumou/OA7OHdeHQAVp5znX7vltFkAfL1crn3u/LkAPPZDMbfff+FsAL7464f8PWdfK/sfuVMikMf9xSUArP3TcgDq5s/31zZvk1RF4RQJM7Ts1IBddYMcN3fLcWm1v6e1Vc34ojIA2tv75Ti/EIDO7qhZD9AdM+N7B4Yjx5EAnZGQSb89p2b94MjeyHGyAN1wLIiXNEAX25cQsEtmkjN6EC+Z+Z2OqT8WnKl/8OHKZR0csgQZZfbpVcV8/arj2djcC8Dnb1zqX6splZTYwgvPAWDxjAq50HgiAFccOwWAL4bSadedLKz8yIAE196yRI7XPrwDgGPnn+uvbV25AoApZ0lwsGnVegAqGuS+nXvEgsipqvf3dLZr0E6DeJ02QFdUDkBXl6beQu/UY4N2muLr7Y8yeyQYp+f81Jsy/WAsFTcUPk7B9skCdAnBtjGOk+2Js3+c+WFsBk7G9BPF/g7pwzG7g0OWIKPMnp9rqC8v4PKfiU99381Bwd2qrcKsf3uFpM9ylMHOOO84AGbUCnsWHLPY33NiQ5X8UCr/XjZX/P0f7RUf+Mx5tf7a53o7AJg7W3zypmckPTfpZLn/Gy9uA6Bq1kx/T3e7+PF5lbKnt0ssEoqF2Xt6Epm9t1eZXf36Pltko0w/MBAqurHMbtlej/1Umz0O++fK/kP2nGX62DEkpt7ifn2y1Fuijx73xxO27JefH4fz8w8+HLM7OGQJMsrs7f1DPLBqOy/e+wAApR87y7/22YclRf/LD50GwNodwqofeYtE6e1f7JNOO8bfM7lS2LNgpkTd59VL1Nz62GfPqPLX/ts+Yc8TZ8m5x/vl/rOmS2zgjSf3AFBbv8jf09EkpbmW7X2mL5M9/T0anddoPUCfjcZrIU5/f5TZ+/tD0Xgtxhka0nM+s0d9+EjkPe6z65pk0fiRvVG2j/vf6fjsYzE9JLJ9Mr8+joPF9vvznGyBY3YHhyxBRpl96+4ePvmtP8K0BQA8b0tYgRce+AMAFR8Xtv/GH9+Uf69cCMBmzXm/57Rp/h7r1x97vOTO6yuE6U3DHABm15QGD1f2PblB/G2U6ec3CEs/rhH9KVMCln6zrwOAqhp5h46tUvpfMVWi/v29wuw5JcGewT714wvl2QO2ESZP3m0wnGfX/PzgYNRnHx6O5tmHRsLReMvk8Rx6YjR+rOj7vqSR9Tizp9M8M7pfnw7Tp4OJYPpshmN2B4csQUaZfV9/DwOrl/Hlf7sNgM/eFzS1MCyM2KQM/sgjrwDws788GYC7X5JW13ctbPC3tHTLnvNOkFx5QZ787Zo2W9bUlRcG96+SNbOrlO3Vhz6hQRtfNILfOKnc3/Kssn1trazZ3C9tsaUVUt3X1SJ+fml1lb9noN/m4uU5QwPR6LzP4pDI7L4PH2X6kVF9djn2fXYT/P2OR+N9f1z3JPXZx2iWSeaz7w/hjhXBP1jIZuPAMbuDQ5bAfdkdHLIEGTXjC6uqmPu2q7nl9EYAvvz5H/vXFl5+KQD/uUKKW7w3pby1d/D9APzPExsBuPWcIPX23EYxoy+dK8Uztslk0XwpeS0tDFRnyqdOBaDWmvba8DK7UoNratrOqw8KZBgRE3xKjZr6g1JUU1UlabWd/WLmF02f4m9p2y1Bx4IicRMGB2zhjdxjaDBUVKOmvZ96U7M+bsYPDycJ0I3EU2+JRTWB2Z4TPU64HuwZqyAmWVFNHOkU4qSD/SnDPRjPOVrgmN3BIUuQUWZvrC3lpzedGhSN5AcBtG9ccwIA7/33J+XEFAmCrd8p7Nn0wksAFBVc6u/5xcpdAHzp4nkA7O4UFj13Xk3Cs6fN1LbaYv2Vq4WN68r0HbTkdU51iNn1T/5Uy+waRKy2a5TpS8uK/C17Nsu5wsrJAAz0ScAup0jWDA0OBffXIKHP5MrsPpP7x6EAXTxoZwN0+5IE6MZIzyUL0I2VnkseoMtMIU46cOm51HDM7uCQJcgos5cU5LJ4ZiWfeVik5U9/5yX+tVO1QaVzxTMAnP2BawG4S3142qVttTOk3vrUsiYAvvNOKXH9/evC9Kc1aONKKM21QO9flC/MWDVJ2L+yRIUnSqoAmFYWaNBZ1mysVvZXH76+Qpl8SIpqysMpPj1XVCJrujukxLawuFBvESqqKZA1I8PWZ5f/OYZjjTCR1Jue2xsrl40LVUCiTz6WDw8hZkyRnksuXkFszcFhV5eeOzA4ZndwyBJklNn7hvaycksnP/3+/wHw1I8+4l/zWbhYyldvv1D88Bu++bScnywlsJtU+AKgefVrABTkXQnAb9a2AvAPF8ne1u5A1/2UWdIcY1lnylRhej9iXykRfN+nB7+ZZUZl4JMDTLLHyvQVFYnMXlwi/jgDUiRUUCXFOoP9wTuZfFkzPBRtlkn02ZOIV6Ri/3FE45OKSozB5OmU2CZeT3Zu/K2z+wPnwwdwzO7gkCXIKLNvbu3lgz99AQbEj108o9K/9uPnNwMw5zyRkjplljBvx8oXgSAP/+C63cEN26QxxWqx//lVmQxTc/XxQJCHB1iiZbBWFqpxmlgQhVpiW14j71JeHIhHWitjsvrfljWnVSpr7xVGrikLMfuwRN9LLLNrBN/m3Xs6e/yl+QXyLN9n12aZvSPR8tnkPnvMH4/58JFzin3xcllLeqE9cYaN+/DpCEbsb159vHA+/PjgmN3BIUvgvuwODlmCjJrxg50dvPmbh7niEzcBsKcnKDD56j2iS/evHxFduvxcDTRpwOumCxoBuPP3bwY3VO25XR1iOje9Lqm4ogIxdZ/d2uEvvf4EKZftVKWYBVPFrDdqnlbXicleWhCU2FrFm8oiNe01YNZQria62nc14dSbBu3KyqwZL+9WqGa8Nxz8zvma5vPN+IKC6LE+L2LGx8/5AbrE0te42Z6OUk08oJVWgcwYhTcHq1POYXxwzO7gkCXIKLPnFJdRvOhMvq7qMz9+scm/1vWSpNgumnc1ABt2SSArd85JAFwyR8pP//bl3/l7yo4VpdlVzTqkcaf0vNsy0T9vaPXXfvysRgC2t4mlsHhKaWTtlCnC9IX5wd+//MoqAEqL9GPSktq6ohCTA/WWxcHvi68ojTJ7sQ38DQ0E9y/UfnZNx+Xl5ekt4gG6RK15/1y8qCZZgE7P7UujqMZn4RRr9mfM8/40z6S7b6x3Sbxn9jbPOGZ3cMgSZJTZZ04u459ufQt16vN++2cvBBePEQavVZb8/G9eB+Cc80XXfVqNNp/seN3fcvoV7wPg16uVwdW/71bdt/Xrmv215crOG1QhdnaFtLb2aSpupirT5uUGf//KtRCmxPrxqmNXo/63ZdlJZaF0nWrbVdgyXGV6n9mHg6KaeOqtsKQwckxevt4ikdn91FuKY0jis8cUaONpNRhbmSbCjH46bvw0d7BKah1SwzG7g0OWIKPMXlVcwNsXTeWBVVIMM7hmmX/tQ1/8GADb1Kd+4P9eAeA/b78YCLVr5gavfO0pojX3lV/qWPgKKXlt1lbXPZu3+mstY7+wTWIBJ50qRTvdGp2fUx9qgFFUVotfX2T9eC2yKbEltvoutSX5iXtLooU3JXbNSBCNLyi0bC/n8vI1jjA0CrNrNN73xxMaY0ITYUZirJyqMSaEBP87dj1ZBH+sktp0WNxF5w8+HLM7OGQJMsrsw3s9WrqHRDseKDz+DP/ap89pBODnrwjrD78u/vxpM6XVdVOLNJTkzAomtpw2XeSotq7bDEDpbJkM8/oeUYGldYu/1rLYyqZ2ACrPE3krG52fWycxgbDgQ12dsL1Vrc0vVx++UD82bZSpKQxF4xW1pVGfvcRG9EcCn70odi4vX46t9ryNzu8Ll73GI/TK7PFIOySLxkeP45F3GMVnt/dIK7I++nH69zlweSs3eSaAY3YHhyxBRpl9W0c/n3loNQOrxVf/3L980r82VaWe7nxI/e86ma9mtd+/+9xmAE5YGghOTlXhR5tfX3jeOwB4eqPm3TU6D4EY5aZNwuw2wr6tWyyG6WXy/MGQBJQVmszNER+3RCvefB9e8+6VhSGf3VbklehH68n9/AabvYF4RaG1ENSP96PzIxqdL4o1xoDvx+9L5bOPEo1PZz67543u1yfPhydG9ccLF50/+BiT2Y0xM4wxTxpj1hhjVhtjbtXzNcaYR40xG/Tf6oP/ug4ODvuLdMz4EeAznuctBM4APmaMWQjcDjzued484HE9dnBwOEwxphnved5OYKf+3G2MWQtMA64Gztdl9wBPAZ8b7V6dre389u4HmPs2KYm9+bSZ/rXXdURz6wsSvFt6rZjk3Try+L4npAHmlivmBy9vm2W0UOXCRVJS+9sVoldHYZBOa++V+zRvk0IbG3Rb0yLKN1ccKwUzvUOByTxNzXjbLFNWaVNxairr8MaScPOMpsZqfTNezFPfjN8X3L+4OLkZz4i8a26ePH/v3sTUW6IZnxhs8830FD3wcTMfEptlxkrFJV0TD6zth7pNsvumA5eOS41x+ezGmEbgJOB5YLL+IQDYBUxOsecW4BYACiv29z0dHBwOEGl/2Y0xZcD/Ard5ntdlIlNEPM8Yk/RPqud5dwJ3AuRUTPcoruDuD54KQE1pkLL6q/tW6hvJuc9eIjpya5TxdywXxZpLPnmOv6fNtsjq0MaLZos2/HfvlWky1M3y1zZ3Cfvvbd5qfx8AVqsu/XuXTAcCSwICVVnLgJWqPee335bIHy+f6cFPjVUURAttbLmuLbKBUIBOzxVYC0GZ3abi7GhogJxc2/gSTb0lC9CN1QgzaoGMn2pLp1117GaZicBETZoZC0erbl1aqTdjTD7yRf+553n36+ndxpgGvd4ANKfa7+DgcOgxJrMbocC7gLWe5/176NLDwI3A1/Tfh8a6V/2kKq792JUsUu25V5s6/GuP/eIxAGaccx4AZ82WgpnbHtRUXFcLADPrAj985VZJsZXNFitgho5W7tkqrbP1Cxb4a1e3aTquR3TphlX8YeN2vYeWwO5sD1h0uurD22kr1dVybEtvbeNKuC3WWiYVBdGPtqoo6sNDqDhH03E+s+txbp4WzISKaiyz++dS+PAwSuot4TiJn0/sdeO6daF9Trfu0D1nPEjHjD8buAFYZYx5Rc99HvmS/9IY8yGgCXjPQXlDBweHCUE60fhngFTVEheO52FTygv5wgVzWblF2PSzD68OLnZLm+onr5Zoe7Gy3O+e0JbWadLqWloYvPJ9q0VpdtGSGQDU2BJVnR5z7Pxz/bUvNInvb1nTtrbu2C6ltdbv3h7yjxtKpGhmSK0AOwnGFtkUl8r1wrDPrtNay/L1XZTdqop1TSga7/8uei5g9qjPHo7GFxZoHMFndlsum0Q3fm8KHz2hXDYSfyGM/fHZx3t9ovc5JIcrl3VwyBJktFzWGIlk33TX8wBs/NOz/rXGC2Xu21ULpG31jd0SJe9ZLUKUJ77zCjkeCMpNH9VZbzddJj67ZVzL3mfNqw3WvqJZQi1x7dKou52nbnP2b7YFzD6/VhpfrBUwOTYZpkRLbAtyQ4aP3t8vqVUfuqIolzhKYsxeWBj12S2zE2L23FwbfY9OjRndZ08efY+LWUT3WB89DVmq+HE6zSeuDTbjcMzu4JAlyCizt/QO8cNlm9n4W5n1ZivQAL723iVAMEftq0+qZLT6rx9+ayMATa19/p5tK2Ua7Fs/ciYQyFFZiemzpgfl+nfZqL7m5G2OfmSPTH61efcNLcH9SxfJx2ObaOwkGMtCdnprfkjKiiL5nWyFnmXe0vzEjzqR2aN59zx7j5EgN28j9CMqumFyrORUNO8OiRV06UTjxxaPTCfPfmjy7nBwovpHS97dMbuDQ5bAfdkdHLIEGTXjd+7u4ivfeYKSxWcBMHveFP/a+fNEP85Od/nlw68CUDh/KQDnNU4C4H9Wbg9u2LwJgBm1EhTb0S57zRTpeW+sCQpw2nZImq60YRoAW7SP3ab8bN92U0sweNFqzW1vE5O/Qc12u9aOas4LBejytAfdN+O1yKY8P1o+C1BeqGusGZ8fTb3l2yBfqMQ2XlRjA3ZezGSHkGmfwmxPqiAzhprNqBbtIVCzmQhkS6GNY3YHhyxBRpmd4UHYsY7vfPFTQFC0AkFJ6v2rpSCm/7U/A3DpX98IwFQtVX3o+W3B/VTHvVobav6wQYJt04+RuW714RlsrdIAM3XJXABW75bWVqtmYwtndu0KmN0W2rT1C7PXql78sKasKnVUc06oKKWwWEtoY8xeYlk7tLbcptpUzaa4IF5kEy2nhSBAZ1nbtsUGAbrgf1IvVeptlBbXhIDcaEo1yUpokyCZ1rxD5uGY3cEhS5BRZi+tqeKU69/JVcdPTbh2v2rJf/chLY+tkuKaW84QgQurDffaimCKa+EcUZq1tTSPrBL/e9F88f99fXeAfimLPbZR0nFrdmr5rDKNTa/taenyt9hW1l19EguYXy1FNtYKqLHMnhOwVVGJtsFaZlcF2uI8y+yhiTM+swvzFRdGS2p9nz1UYmsVZy1rWx/eZ/HccOotWmiTssgmWSNMiiaW5OIV40+9uSkymYdjdgeHLEFGmX1WTQnff8+JvpBEuKnlH372CgDNL0oJ7aIrLgPgpBlVQFA+y5ageebkG94NQJcWmLy0Uvz9T73reCA5oyxtlPv96jnVlNfCHluQ07mn019rW1mb2uV9T5oiVsHgsDBtXVmiXnxRcazQJj8WnQ9Fy8sKoyW0vghGisYYCHx2ey43V6fIqCJt+P7eGEU0yXz2lD56ivJZWRM7TlgxNvZHusqVz44PjtkdHLIEGWX2grwcZteX8L6fiWzUW+YF5azNz4p4hWXCz73tWCCItP+LLZ/1AiGHa08T33+HCk40r5c1pzaIdFXvYBDFtnPaTpgkfvd3dnTI+XKRsrLWgdcZzHS3aNL8vW27tY0xk8olEh5moFJ93zzrxxdGp8qEmbckL8rsfjRe75cfY3oIldBq9N332YdkjwnFD+IltPHy2aTlpmPk4pPnw8ff4uqkqzIPx+wODlkC92V3cMgSZNSM7x4Y4an1Lfz2p6JZ+exxJwYXp0ixy6S5jQCce4ykzzr7JBD10BNvyLrpC/0t58wQE/yZrWp6t2wGoEHHQrV2B+ORqRH12BlVYla3N7cDUFAnCti7rEJNT5u/xZq0O9uktLZYU2HN2gs/qUwLWkK2Ypmes731eYWxAF1o5HRJXvTjLyvQNeqqFI5qxss7+OWzmmbLyQl1sCUE5KJqNul0vaUsn42ci+5JNjByLKQ3gDHt2x0QjkALPS04ZndwyBJklNmbWnr48Pefg1IJzHW99LR/7d2f+TAAi6ZJCWyFTkv50wZh7eYVom6z4OIL/D3TaqTc9je/EeVZy4BWj/7ZjUGwrXqaMHiNpsu8NimtrT3xRAA2dSizh4ZBDmuzye5WKa21TNutgb/qwiTMXiL3t4U2+brGpvFsfzuECm3scayIpjBJUU08aGcbYfzGmLzURTVjlc8mO5dOgC4xPRe9noyR0xkGebQyrEWmfz/H7A4OWYKMMvtITxd7nnuMD3/pYwD8+L+e86994ULx2a1vu1kVY378vDSw0CfFLleeMd3fY4tQVryqs91qRWW2SFNkz2zp8NfObBQ9On8yi+rHT5smKbn1LcroIRa1ZbFtqktny2fbBqTIpqpQWHwkpOVWqVaFzYAV6Bp/ikxeUIgTlNDKtdJYkc2oPvu+aOrNsnh+TmA5xEto4z57Mt967NLXdLTixr9nf+DKZ8cHx+wODlmCjDJ7fnklk869lC9cICwe9uUa60sja//+t9IQ8/iT2hgz6wQArpgXzI+0kfrWDRKpr5krKrMj6r8u27DHX7uwsQYIRcV18uvcqcLsvmhFqOilX4tnutqlOcb63S19EuWfXi6R/aHQxJYK9dmtpl1BkWX2aMsrQIE9p8waROPlgym0zB8qJIo3x1hmR1k7XFQTj6QnHo8SjY9H2pP58PYc48dYk18dJh6O2R0csgSZbYSpL+V7f3WG779++pxG/9qmZol4l6lP/V8PrQKgf63oxp92/bsAaKwPpKbetAIUrdLUcuI7ZAKMbWpZv263v9aW1sajzcdPlej/z9dr5D400713UNizt0ueY3Pn2zuF2c+aIcxrfXuAmpKo/FRRcax8Nj/Qns+PldAW50X/9hYWJPrs8Wh8Xl7y6DwkNsekboxJHY0fVbzC7tmPme7pwGnLTywcszs4ZAkyyuxlhXmcM7eO//ijNKx8+ry5/rUP3fsKAG+ZWwVA1ys6LUZZ6SPnzQKgojhgzgdeD5gb4LJFUnXX3Cn+eNvmrf61hbXnAUETi5W0Oq5WYgWtLSpmURo05/jTZ7oC3x9gh7bo2mj5wHDA7LWlKi6hFFOkloo/raYgxOw2Qq+/Y1Es7+63vIboKh6Nz7U+uza9hH12y+T2nM+MfiMMCUhoJElDpDIdbfmxnuMaYw4+HLM7OGQJ3JfdwSFLkFEzfnBkHxube/nKd54A4PJQGu3+//4jAC+dICObKamUf2YvAOCsmdL0YtNhAL9ZpmozWkxz5jRJr63dozpyewIzfrKOW+7QdB0VokM/tVxKbq1CTU5Vvb9nj6rKWv06axI2d0p/u1WQbe8NGm5qtMzXmoslGrCz5bM5If14v4TWmvG5MTM+T03yUOqtIMGMN7HjxHJZ2xyTujEmmQbdGE0ukTXj35MOxrKMM9UYc7TAMbuDQ5Ygo8y+pa2Pj977CuxYB8Df/3ZtcHG3BO2a/iRBt3kXvhWAhXOkzHWKtq2ut6qwwJuvrAegdp4E+qZrY8xPXlJt+VBTS3WpMKpN1xXVC7NXaXnrcLsE4aobZ/l7dvbp/kEp3bUNL3uU2S3Lhq2NCtXVswzpM7vNvBUEzO4H6LTttTDG7CWxIhsIpeuU7eOpt5zQkMl4gC51uWxYNz7eCJPiOISUDDyKrnxis8zh2xiTyecezGc5ZndwyBKkzezGmFxgObDd87wrjDGzgXuBWuAl4AbP84ZGu0dvWzvL772f098nBTKP//Jx/9qkcy4CoPm5JwH426vEd28oFba2uu5Pbg5pxO0UZj/pqtOAIC23Yr22vIYKZEq0QOV1LX2tmyL+fbwxprZ+sb9ni6rKMiK/lp0E066ad5bZu4YC9deKgmjba2mRZXYVsygIPnK/0EbbXossa+vaohiLyzPjRTRRnz1ZuWx+Xn7k2E6NifvwMHZLazrpOlf6enhiPMx+KxCyu7kD+A/P8+YC7cCHJvLFHBwcJhZpMbsxZjrwNuD/AZ820uVxAXC9LrkH+DLwg1FvVFAMM47nB+85EYCT//t+/9I/3yDnbh8SBr9wrkTqbTHKBp3B9qsXQlNc1dd92+Iggg6wUWe+UT/bP2cj3883ic8/fbpE+4tsY8mA3L9hSpm/p6ltIHJfWxbb1SnMbpm5YzBg9qlqiVjhi/LiaDQ+7LPnxgQtEnz2/ESf3Y/G67nEIpuQbrwXU5y1t4kX2SQtl00VaQ9H1pP713FeT+7nj7/wJh04qyI10mX2bwKfBaw9WQt0eJ5ntZq3AdOSbTTG3GKMWW6MWe4Ndidb4uDgkAGMyezGmCuAZs/zXjLGnD/eB3iedydwJ8CM+Yu9W299q9/M0njhJf66y4+T2W4b3i7TXGpi01Z+ukIY/ZUXg1lvuY3iX5/WIP53u+bQe7c2AVB/3HH+Wtv2urpJhCaPm1kFhHLdOil1Zn3A7NtUjsrmwQd0Ekyfzna3VoefjweOqZL91r+3jT0WVswCwj67rEkon81P/FtcEPPj/ZZXPQ5H44nl2RNnvyXm2eNMntgIk/BKCW2w+4O0BCezpGHlYCEdM/5s4CpjzOVAEVABfAuoMsbkKbtPB7aPcg8HB4dDjDHNeM/z/s7zvOme5zUC1wFPeJ73PuBJ4N267EbgoYP2lg4ODgeMAymq+RxwrzHmn4GXgbvG2lBXWsjNp87iKU2N3XH9kuBF1KS94UTRmNu6R0xlO/zxkSckzTay6TV/z0nvuhIIVGY3t6jZ3bETgAULzvPX2g62zZskxXbtGRJiiPdvz6sv9ve8vE5TeAVyzhbP9PXIu9mg2+7uIEBXOEP+ftoAXUWCGR8c+51wql7jH6sJHe9vByhIUJeNKdfkhM346Dm/v90G25L0s6dMtaXob5c18c6yNEz/xFPjhutvHx/G9WX3PO8p4Cn9eSNw2sS/koODw8FARstl93ke/cN7ufl70qu+5t+u8q89uaEZgMsWSqDua49vAOAU1Yhre/UFWTgcpMPeebpYAb7G/Dad5qLBtrPm1vpr23pVr26HFOXM1UDaoFWZUfaeUx0we5tOgrFDIftUucbrCcY6AzT3hJhdA2Y2TVdVHP2IC5Mye2zMs9Wvy03C7LkpUm967BfZQGKPux97S60um6gbPwpLpzn8cX/625PdZyKQXGln4p9zOMKVyzo4ZAkyyuw7ugb4x0c30PZnKZMd2Xelf+32/14JwGm3Cxv/+CHxzV9SH942ozBlnr/notlSTGP/Mv9ulSrXlFYBcNaMquDZWghDi6TlGsqlscZXoymRtdPKghLb7natCyiX1J6dBGNbXi3aegb9ny0723HRlUXRcclFIR/er2wtUJ26WOqtIFZkA6EpMX4jjPXZ5Xm5YWvAS556s8q3vs+ek1iIk1ZRTXxPinskw9Fe/HI4Ktc4ZndwyBJklNn3tHRyzw8fYdK5lwLw67U7/WtNj/8egMffLVNa25Y/A8DT7RKxzznmRABmzQsK9WbWin9txSNee1VS/TkNc2RtTaBF/+t1WkLbK0U1VdryarXnqRQroTKkDtvbKcxeVFEu76+TYBiUqL9tdmnrDpjdFr209QiLVhZZMYtEZvcnvebFdOp8MYvEv8WBoIXcLz93FJ891hxjmdwXs0irxTX6/NFnvSXnjlFJzhbvpEGE2TjpdSKf45jdwSFLkFFmx9sHg73c9VdnAvDB7wez3qiUxpdv/J/k062++vCGFQCce9N1ABwf8sNLNLK9fqc0sXS+KXtnnnoyAHWhktvlW9TP9qJlrG/oJJjyGmmMKQ/nxbslul8+Xd6tuS/a8mr98K6Izy6MaEtrS/OjMlVhZre+c67mznNjLa/JovGFsXN5sTx71GdPzuSjRePjba+jileMg/3je9Jh4LEELQ5Dt/iwhmN2B4csQUaZvaquiktufgfnzBPxyJbnAvGKSz76lwD84b8eAWDmOTLdZcvTIk55y9kzAZhSEuTBbST9qS2q666Vc4vni/9dEpqK+vomzcEXi/9tNdnf6BBmr6mvTNhjo+7V6vvv6NKGF83j2yq5rq6A2S3Tdmmrbqn6476YRWFiNN62vebFfPYCGyUPMVtRLBof+Ow6nz3SCBP12VOKWYw6xZVRj5PBiVkcnnDM7uCQJXBfdgeHLEFGzfjplcXcccVxvKGqM0wJxj/906WiD/+HH/0cgE+/Q46/uEfSX6fPlGKbvFBqyTa+/OE1LabRwNa586QIJmw9bremfrUMeLTBsJU7pFhn8mQpny0MN59oiq2uTgptdnRGJfZsz3pPKEBn79szLCk963ZYM76kMDFAl5cfS72NEqAryI2m3uLKNZHUm2/a23FPoyvXhNckDn9MplSTutAmjGRX98fUd8o1BwbH7A4OWYKMMnterqG2rID33f0iANdc/xb/2vypEjgrX3IWAJcfKw0xz10gKrP1FYUJ97vzeSl9fe1V1YmfJJpzp06pAoKSVYCuHRK8q5wmzG6ZdsNOCcJZhZq8MJtqIG5qtTB7iy25VdazzS79PYE+fW5Ml25WhQT3rFJOmNktEpk9dhwKoMXVa+IBury81AE6YuWyySfCRM+NNe0lci6eijsA5ZpUz3LYfzhmd3DIEmSU2dv7hvjfldt46RcPAPCTh7/iX9veJux4w9UnAAGTf3ipzHGzabb8kE/68PPC6N0bpZim4SQppmnQNtWW7pCP3b4DgOlniW6dLXrZuk3aVc+eF7TDxmHLcp9erYU5WvBj79HfGzC7JdH2fnlf61Nb/740CbPb1FvcZ/dTcSGGLMiNsmX+qD57tKgmfhyfECNriJwbdW6bIlGnbnQxi6T3TVgxNpJp0o0ZP8hiMQvH7A4OWYKMMvvW5h5u/dYfYaYoyDbWB40qn35oDQAfP3MWADt06soC9eVf3yFR+bDq7JoVb8gPHdLkcvqJ4ufbuW6v7QyJTKgu/HGNEqm3lkLLTmmMmaPsbX1rwPedG6vFynhQ38kKXQwOy9qR/oDZrT+8pzfO7KojX5jYtlqg02pyYj57vOUVEstl0ymq8c/FxCy8EdvimlpddtTGmP0pl3U4ZHDM7uCQJcisLFV/D4Nrnucr//EpADY19/rX7v75nwH4t6tE6/27z24E4BPnSLvqj5fLrPVz51QGN9y6Wv7NF+a9fKGU4dpS2Ge3dARrlR2XzhKJqQ6VqeptEVHJGSpaYdka8Bl8Sqn46HYSDEUSubc+O/09Cb9re5/GGGI+e5jZLWtaZs+1vrP+Psmi8fkJjTDRvHty8YronHcTa2ox42pxHcVPHkeL6/5IVR0siyExxnBwnnOoBS0cszs4ZAncl93BIUuQUTO+qKqaeVe+nZtPlSDcx+5fFVzc9DIAXZqy+t6DMjD2uhNEg+53T6wDYGf7jMQbT5ay2xOnVANBkG3ZhtB4Z9WlW1QvAb+d3apS2ymlttWqUBMuxLGqspNKxKy2Y5/svXq0s42BxBl2nX2S9vP721VzvqwwcTyyNeN9azo31t8eTr3lRP8+x8dBJSuXjZvxCf3tYTN+XIMdU5nto6Ti0tzjMPFwzO7gkCXIKLM31pZw1weW0q+Brfv/+4/+tcql5wPwp40SMNu9TK49v0UKZbpekxLb5UOBRjszJIU3fa6wf0OVBtLUOtiwrjlYWy/98FMrJOj22Ea91i+sXKGjlbsHQsxeLoU2VtXGToIp1GBex6AW7QwHjTC2wMQyuy2/taW15QVBgC6uS5djG2NSaNIB5MeYvTAWoMsLX48X2oyhSSdbUijTpAjYJTuXnrpsiguj7En7HiEcbZp0BwLH7A4OWYKMMntxQS6LZlRy24OaMtsdjF/+wudFQ/6OX6+P7Lnz2S3yg+q+9b8R+PnHXXax/HuMFMpYBrYFOG1NW/21k+ZKk4wtylm1U9N+ynalmhKzxTwAxRVlek0/pp4OOZ50jNx/YCjybhCwdbcq3tqSV8vsJfnBR57KZ8/Ni/nsozB7QZ6JHOcl9dmTl8smtLwyhr8dP07B/nHsryZd/NxYmnRjPusowIH8fo7ZHRyyBBll9r6hvbza1ME9P3gYgEnnXORfe49G3T/7xf8BYMqZ5wHw7FMSlc+fJ7778Osv+HuuOl0i8/Pro6Wua1u1TLa1yV/bePEpQMDgG3ZoU4tOULWFOFvVLwcor5bIfbH1s1WTrkz9/hYtiWVvEEcY2WcFLazPLizUPyIWRFFoyste/TNdXBD12Udj9ni5bEGsXDY/ibqs77OnKKrJSaZBZ8/5jTFptLimOE4GF33PPByzOzhkCTLK7Jtbe7nprhdgSPzi//f+k/xrlnGtQuzH3i468f/w6T8AcMFHRH32sdZd/p63zZsEBIqwrdrS+tSbyuyhKPnxMyUHb6Pj27S1lVJ7XthuU3swJbZGVWX9+Wr63tXaQtts57KHWGqvlsX26aSZQKZKrICS/BCzqxVQmB/12a2YhWV6coL/mXyfXa8VJvjso5TLxqPx8RZYEvPs8TbYdGSpJkpyyrH/xMIxu4NDliCjzD7Y2cGm3z7M1bd9CIDLF0zxry3bKLruxYtkWsy7jhf5qH8olJz2LWdKnnzNukX+nsZ6uWaZa5Wy9Yr1kqu3DSsAp8+Un61f37pLdeSr5R2sH7u+OfDZ61Vo0veD1VKorpR8fmtPVIASglbWfp0eY5tbekeE2WuLghZdm5MvLrTMHvXZc5L47Hmx5piEee1JxCtyc1NE430WD2+xba9pzGePI54jHy03P8pt0oUToBwfHLM7OGQJ3JfdwSFLkJYZb4ypAn4CLEIssA8C64BfAI3AZuA9nue1j3afnJIySpecwx1XSM96TqiY47P3rQTgPVctAYLS15olpwFwygwJpF14xkx/T3lxMF4Z4NGNog2/aYMG8SY1+tcW1EhTS++gBKkGWqRctmqW3M8Gy5pagt706bUSoMuNBbgmVUqArs3qxYfM7CEN0A30DUR+R9s0UxBSf7VpOpt6s7ABuryYck3kXRT5MU26aLlsrDnGpt5S9LfDaEo1o+nGR14hrSKa/UEWW+ATgnSZ/VvA7zzPWwAsAdYCtwOPe543D3hcjx0cHA5TjMnsxphK4C3ABwA8zxsChowxVwPn67J7gKeAz412r5mTyvnqredSUypBqsfX7/avrf2tpNj+86YvANCswxKvuOBYIChzvWbRZH9P36BVnJW/WU+uEkbv3SbFNJMWLvTX1pVLm2q7lrHSJcw+ZapYEoPanLNrV9CuemYKxdmGSrnXRtWcDzOvLYsd7Jf3tyTaMSD3D6fGrDVRFErHQcDsPgmGLId422tcbTZ5gC7aLJOqfBaSKM6OoTYr52JKL2OozUKiastEBfHiirPppf3G/5wjUXE2HWafDbQAdxtjXjbG/MQYUwpM9jxvp67ZBUxOttkYc4sxZrkxZnl3+56JeWsHB4dxIx2fPQ84GfiE53nPG2O+Rcxk9zzPM8Yk/VPned6dwJ0AJ5+y1LtiYQP/u1L03r/6qzXBQtV7m6sz1/5zubDzB0+eBkCnFqksmFzhb9m6R4pcKlR4Yu0qbXzRwpwF88/z11bpmlXbtZhG1WYbp8n9+lVcYk9Ll7/HqspaBrYM21AhVoY/qll15CFg9uEBuWb94Y7+RN37EfXvywpiirFaxONr0uUGsYmcVKk3uzcv0WcPmHx0TToYr8+efAKM860PT6TD7NuAbZ7nPa/Hv0K+/LuNMQ0A+m9ziv0ODg6HAcZkds/zdhljthpj5nuetw64EFij/90IfE3/fWisew3v3Udz1yC3flOEKQbXr/CvnfGX7wYChv3mg68DsOxL0iyzQpViz54b+NH3rdoOwAmThJ0HNot0lZ3Rds6xdf5a28zyWmuX/cWAQJfeilZ0tQXMPrVUrI1hZWvbNDNF4wfd3crsapVA4PszECjnAnSpzx5uVLEFOKUFUZ89Pz+uIx8we9xnz49F50cVr/B9dJtdSGxxDXx0uyUN3zoVlY+jeSYb1WYzjXQr6D4B/NwYUwBsBG5CrIJfGmM+BDQB7zk4r+jg4DARSOvL7nneK8DSJJcuHM/DtnYM8OmHVjO4Vj2Cmun+tTuuFImpZZsliLf1macBKCm8DICfvCD++Omza/w9978ozL5rgTak9GgJbJmsOWN6pb/WstmLTRptV232xVMkl26lrLyOFn9PbbEw+KBldmXw2iLZ6894C5Xl+rrzQ4EIBkB3v7xjOFpu/fvigqg/nB9rjCEvSZ5dWTMvJmaRF4vOQzLBScvsI/qcRJ893gZ70BphRpWuOkooNQUyrSPvKugcHLIE7svu4JAlyGjXW1drO7+/+wGOvfLtADROD9Joi2fIz5d8WzXmVNdtV4eUnT76hATsdl0239/z6osyImpIg3poh1xug2jEzaoOBkdak3ntZmvqS6BvturM7exRs7s3qPi15bh99v6qI19VJOd9M7643N9j+9atGW9NUd+MDwXDevSdbOrNBoJs6s32s5uQuo2/XdOA8QBd5FjN9rzcVKm3qMkOQVFNkK7TC+movo4SkIvjaDfRD0c4ZndwyBJklNnJzYOyGu76gMT6wk0hVmVm+e+XAVB76rkAPLdFprr0rV0u17ef6+8Z2STNM+u1/5tpwvrTj5HRzbXlQe+4ZdatTRIANDXSx27HO7+go5vDgTWrntOtwTtKJeBn03iD2rNeqBNjALqsrv2wWCSWre2I6PDgRVtUY9Vr4oMe/cxbbupy2dwY4+YnKZf1FW/iqbd4Ywz4TJ5egC69Ipr0JsKMcoMJ1JI/GnXk032WY3YHhyxBRpm9vr6S6z/2NhbNqEy49s+PqV58y2YAPvw3VwPwo6dVIVb/fN370s5gk/r1g03iz885X8pjj5sj/nhJqFhle5swdsd2aZapmSlKOJVaRruuWRld21ghYPCdqktXpJNgfLXZPinAKa4P2m67LbNrYY9ltd4kPrstqrGKsXEdeQurXAOJirNj6chDeKxzch35pKm3lEo1o2jFpakjH3p0IsLxg4TCm/jxATwnC+GY3cEhS5BRZp9SXsjt58/h1aYOIGg7BfjOz6TQJm/+qQBcv0QaYL72g6cAKD5O/Pxlz28Obtgg7a/skDLZs5cIWy9qEAYO/1Xf2qnacm3ShDP1TCnisezvi1aENdo1ptDcL8xeUh5j9kEpiS0pC8pl9/RFteRtE41Vmw0z+4BG462WvGWqgryoJl1OyM/3/W+/qCYejU9shMlL0KBLwfQkasmn1JEPnRtLvMJF5w8POGZ3cMgSZJTZjRH/8QM/ERZ/69Jg1vqQltBe8zcfBmBGrbAoTRJxv/ATNwHwyE8f9Pcc85ZzANjYJmWzl88XX31SibSc9oRmrb9sRSl0autsbW21GYEdu5XZNVcPASPu6BFmr6gsieyxkfvykIXSZiP3ylSW2fvVZw9LcdkpMcV5ltn1Ffw8uxyHffa44mxcRz4uUyX3SVEuO8qst8RofPLS2FTnxoJj8szDMbuDQ5Ygo8ze0jPE95/bzObf/R8Ad68LJsIUHn8GALedPRuAPVaTvUQi9x/WuW6PfLvN33PZ6RIF/+F6ya8vmBRl6xYrLgGsaFLRCmWshQ3leijHLc3a2loWtNDayPfmNrlPlYpg+oIRmkuvqAgxe29gTUAgKjmgefawi93na8nL/n2xCTH+e4xSQRf32ZM1wuSlanEdRbzCP2cJOFl0Ph4FT7MxJl1M1H3G+5yjFY7ZHRyyBO7L7uCQJcioGb+zuYuvfvtRSpdIYK331Wf8a5+641YAjm2QxhSrUzfp5NMBWDK9ShZWBSOj3nWcaFw+tlDM+cnWnFbrctXODn/t+k1q/qtbcPxkaZKxKjSde8TMz60K1G0strZLIK5G9eL9whYtnKkOBeg6+6MjoWxJrFWbDeu+D+yVAJ11C+wI56L8aOotEqAz0QBdfBxUtBFG7jdWI0xOJF2n/8aVavZHNz7Z9RQltvtjSI9LNcfBMbuDQ7Ygs40ww4PQvJHv/tNtANz2g+DxN58q7DysTPiNh6V89uoL5gJBWWvd8Yv9PcdMEnY++wRpfCmKlZk+Y4NywM6t0lBDnTxnphbI2PbVkXa5Xj17tr/HDoHc2SYFObPqxeqIj0CuKQuYvaVLRz4r89oA3dCgMH44GNY7ZHXp5JxN0xXEA3SjlMvmxIJk8RHOEFKptcex8tnwYMd40G585bL7wR0HMCHGYXxwzO7gkCXIKLOX1Vax9H3v4IqFwsStN57iX6vWKTF/1nltbzwlCrR3f/AzQDDJ5S1nzPL3VOmevzhW0mUDquxq/djnN7T6a/t2SuFNzdw58q8qxHZpsYsVraibtMTfY/3t1lZh9tNDyrZh1JYFrbQbbfGOTomxMYGhAXn/sEvdPRidEpNqQkyY2eNTYnJiLa/xVJzcP1XqLZnPHj2XckJM6Fyizx5TZ03SV5qo4JpsTew4YcXY2J8JMfuDI2FCjGN2B4csQUaZfWZ1Cd+/Zok/x+2axYG67Kqt4l//y2Mb5ES/FLnYCTHPKeNfuySIxlsmXzBJCmRsEU1JofxaG9YFs+TolJ8bZ8tU2AqVnNrcovruOiGmYXKgFGvv394ma6ZVCoP7TKXMNrk80HXvscVAqvVu21iT+ew+s+dEffaimN+dFxL5iEfjfSJPFo1X5KaMxicW1aT02Ucpl40jPiHmSMPRGtB3zO7gkCXIKLMX5OUwq66E997zEgD/3w0n+9f+9qHXAHjxMZkSU3mS5OJtU8idy7YA8M23L/L3WEGKaTWS//7TG+KjT6+Q4/amLcHDtWnl+EbRlLetrVu6tfVVc+azJgXMbiP13R3ih08ujc1+U/auKw2YvddOiVVdeit0yeBAwucR+OxRZi+JzX4LM7tPlvrsBJmqnMS/34nR+BQtrxB049hTsbx7BAltsMmZPJ2JMEcrmx5OcMzu4JAlyCizdw8M88S6Zn5/9wMALDu70b/24gMyn91OdXn/X18KwA6VhHrqSZGeqn9/EMF/dIX44TdMlgj9b9eLX3/ObJWo3rM1eLhGx0+dIf69nXa6erf67MpK8+oDIYpeZd7BTmH2Om1YGdobnf1WUxhE4/v7lNkLJI/vM3tsQgxAj97fsrON/hflRRkzL1kFXW4sz55CzALGboSJMHsKnz1p3j3NaHwE48jFjzUxJXnOP+3bp43k8+Un/jly34Nn4jhmd3DIErgvu4NDliCjZnxTSy+3fO85f/DiZ+9bGVxUzTaOkR73D54iabmnN8vY98F1y3Xh+/wt9764A4BrTpC1z7wqxyO2EGQ46Ge3DTQLa8XEt6bZmp1aBKNDG4+pDpRqrNY8PeIelGtKbyg26LEqZMYP9A1ErvlrhxMDdH2qpGPN+AEdClmSH9OCz08doEsoqkkSJMtPUJeNrolsGY8Zb7ekSs/tj7pNFg96PNhwzO7gkCXIKLOP9HTRtuxxPvqPHwfgh//yn/61RVfIaObGqcK8s+qEYW/62WZZoEy2uzNgyBUvyKy33ddIieubayUg5+uuh0Yp500SpZtJFdGU2MZt2ixTUgXAtNIgQLerT4NqWnBji3X6/dly0ohTGmrAsa2sFMu1XlWjsRr3YXayzG7LZUdUzaYoPzr7LVlRjdWNixfVJAvQJaTeRg3QRctlUyrXhJ45FuM6ddnDA47ZHRyyBBll9vzySiafdxm3ny/NKD/8t4BFv/5uaV21SqtdqtL6yp+k2KbseNGNXxkSpBh4Qya+rm2+AIB920Q/fpOqyzKp0V87aXo9AFUl0cmsO3fo/apECKOiJCiQWb5bmmNs2szqxVtGprgsch5gcEDnv2marnc4zuzB59Eb89ltUU1xLPUWnhDju+yaehtr9huEfXarCZ8iFQeJba9+vUw6GnTJU3HJkE5bbOqpMRM3+w2OzvlvyeCY3cEhS5AWsxtjPgXcjPydXwXcBDQA9wK1wEvADZ7nDaW8CdBYX8r3P3qGX+Rxxjsv9q8tbawGgr9+v1mrM922rwXgsutET/4Xr+wKbqi+9G/W7Ykc923bDMCkRUFp7ZxjtExW/e6te6RMtr1Z2LuiRmIF5UXBR2JVZa1IhfWl93Sr6ESJxBUiarADct/CarlfjzbT2GxDuGii3/rsyqxWuKMgN/o3OFm5rJ0SM66iGkXcZ482wniJ5whfHjuyPurxOEpq43vGmv2WbM+4nnOUY0xmN8ZMAz4JLPU8bxGQC1wH3AH8h+d5c4F24EMH80UdHBwODOn67HlAsTFmGCgBdgIXANfr9XuALwM/GO0mZYV5nD23jq8/+QYAd1x5vH/Nzi+3/u+/PqJTXSvE1775VImmX/+tp4Mb1jcC8NyragWUVsm/HcL+x82/wF9qJ8daVmvTVlSvTdZWz5XZciWFocmv7dESVzv7rWNAWLpYI/eFIeZlUJi9yE6lGbKz3+TfMBvFteRtO2yBP/tNzkeZXaPwyuxxMYukzB5juZTlsyEk5NmT6sbH5r/FfelDMF31YJabHukYk9k9z9sOfAPYgnzJOxGzvcPzPDsRYRswLdl+Y8wtxpjlxpjlLa0tE/PWDg4O40Y6Znw1cDUwG5gKlAKXpfsAz/Pu9Dxvqed5S+vr6vf7RR0cHA4M6ZjxFwGbPM9rATDG3A+cDVQZY/KU3acD28e60cDwPjbs6uGr334UgL+5/6P+tR88twmA06dKoG7NE88CMHWpjHBeOFW61drWvObvmbZU0nFvrpW+9cJZCwAYXLMMgHOODTTj5tWKyW014TZ3a7eblsJOmSJptLBJblVlbXdbvprOrZpeKyrVcVBhM35I9hSXyJ6Ofg3QaTAsrMfmm/G2XFZ15ItybVGNp++UmHqzRS/x1FtekrRUXrxcNmZeJ+16i5ntOeMoY52oXnVXaDOxSCf1tgU4wxhTYsSRuxBYAzwJvFvX3Ag8dHBe0cHBYSIwJrN7nve8MeZXwApgBHgZuBP4NXCvMeaf9dxdY92rqa2Pj/z3CmiWMtfW7iBT97WfSaPL6aerbnuX+PfXXCAFOOWqGWe15AAuOkM04O955kkAFrz9bQC8ukWCe2dMq/LXVhXJfjvGedUuZXZtlpmpmvB5obSXVZW1Y5wti+7W4F55eRJm1/uVqvJt50BshHOIrQZtUY0y7eCIDdBZZVcv4f7x1JuJpd7CE2dSjXEeT+pt9H725AG59HTqMqP66hAgrWi853lfAr4UO70ROG3C38jBweGgIKPlsn3t7bx834Oc9f5rAPjRC03+te4VohP/WKso1ZQskhHO1y2eCkBrtxa4lAd++DWLpMT1Hk13nb9Y2lhXvyzWwKyaoF3V+ts25fb6Dm1tVTaaUx+stWhvkyId2yRjfdvtnXIPO6o5ku7S4pky1ZLvtD67vZzEZ7fEan32UtWvs2SXn5fobVkteZ+0c+xxkkaYnBQ++ijlsqmYPdIIkywdF8Y4FGmTIb7LjXA+MLhyWQeHLEFmZ70VFGNmLeJ77z4BgNM/c79/ycwRpVnvTVGXve7GvwZgtjLu4+tFxKJyfjDrbf5kidBbMYyL5wjrP3SMMHxNaFKLjUC/vlsYfZNtbdU22Hl1Eq23890AejvFrzcVNZFfY7fq01fojLcIc2rxTLk21PgCGPZyiNmHh4Yj+wdTTHWNRONtw0tudNJrUmaPa8nr/VIyfWhNApP7t0hHvCJ+PXQQXzOO5pn9wdHK0vsDx+wODlmCjDL7tMnlfOaT5/vCFENrn/evffhLHwPgx3cJa/7VaRJpt9HxO5+VXPqZpzf6e+yMtaLG+QAcUycsvXi+FO+UxKa6AqxqkUkzu22rbKX4/dPL5J0GhwNmH+wU9i+bJDPbbXS8uVPntetc9qjuurBzhebZe7S01jKYVZAFGB6Msn7/SFRt1j4vmc8eNMLoCWXMZKWv8Wh8ntWWV/88NzeJz54iYp98PnsKX/oQTHV1RJ4ajtkdHLIEGWX2upJCPnDqLJ5YJ/530aIz/Wu3qYb8xt2iC29nr2/TqS/PPCWtrnf9XdAWa1nyuMXSJFOnTP+WedF2WQgY76UmYfaOZon6F2kJb7UysRWUkANtf62W3L+dtd6u0lhzplSk/F2r9H7WCojPa4fAZ7fxhD61KvzZb7q0YBRmj/vsEWL3p8TE9sZ8+GRkGvjso7S8psnC++s3x5taJoK141Nd5b7ZYQ44ZndwyBK4L7uDQ5Ygo2b8Ps+jb3CvaMcDt90QFOBNrZbU1+1vnQcEGnF/eFPKY/e++TIAJ099j79nZ4eY02/VYhobyFo6Wcz4npBJbtNZr28S85126WOvmyvNNFahpnsgZMbr2OjaWgne2Saadu1zn1wW6NXFUVOqSrQ29abquOHUnjXjrTXcO6RmfG40QFeUn/g32Y6E8s1234xPEqCLBe3GlXpT2ON9+/aFTsb72dNPo+3blyKoNw5kyvjeHyvfy9jbpQ/H7A4OWYKMMvuOrgG+/Oh62pY9DsDNX73cv7Z2u7DoohkS9PrjG9IIc/cTm2WBTlhpqCry9zz4mkyAufgYKabpVVaeomtauoKJMJa5tzWpgIYG32aogk2pKtRE1Gm0qWWSMrttVOnpkjWTyuWe4UIZy241xXKtr08tBR0sGU69jQzZclnZ06/MHlebjWvSQTB2OSceoIs0wmhzTKqWVl83PnT/uJb8aKk3uyVl6i0J0x9gas1h/+GY3cEhS5BRZt/T0sF//eBhJp8nQjfVpUE56y2/eBWAez8gPvQdv5M21TXPvgJA1QkiYhH2SX/xkmjPffddUkK7S1Ni02vECnjVasIDMyuFnXt3ql6d6rjPbRBLokgVYrf19AUvrAUyU7WhZkCVYnu7pIy2pkjeP8Ls6pvXlsR8dhXAGA757AxF57/1DMWKajzrsydpblG/Pq5Blzz1Fv2bnpLpIdFnt7+bXRJh6dhLHYCeezK/OEsyYhmDY3YHhyxBZhthPA9GBrn7o1JMs3JLp3/pifvEj197iZS+rviDSEvRKmWyb/ugFNO09gSCF8uWiQhG7Y1SiPNsUysAcyZL2eyfmjr8tWfOVJroUGZXJjxhqhTv2Aj4m20hn13ZrbFGYgB2xttgr7B/VWFihN365uUFcq2/X983X+4xHPLZ45Nd+1L47EWhohrrD9tovM/AuUmi8b7PHnlMgrps8imu8eNEnz3hXIpo/KiR9nFYA+kox44lkTVRiD/nYE2VmUi1XMfsDg5Zgowye3VdFZd++B2cOVei55d8+5ngYrew8r//SdjaMjrVIl7xoZNlBvvru7r8LT3rZdZbXu61APx6jdzjquNlzwsbWv21fjOICl1Yjfm5VWIFWJZ6oyXE7Opnz9Toft+gClH0dgBQoewdYWtlcHttaCDG7CMhK2AkOkCnfyg6+81Omk1WLpvKZ08W7M6L++yj5dnj55JJV8UwViPMuOazjwPZUuY6UXDM7uCQJXBfdgeHLEFm+9kri/na5QvYsEu03V584A/+tdkXXQrAw/8nZbEFx50OQMPMSQAc2yDm9mcfWRvcUM1pOzrq+Vck+NZ5xUIANqwLlGhLrTqtmru2j31qhZjXNsjW1NIT3L9QgneTS6RvvWNQzW4dIGlHVQ2GTXM118vy5aP1zfhCSQdanTl5aNSMt6m9xABdYEJby9WOhPKvxHXkITTGeXR12dE06IJbpQ7QpRz/lAwp1qSjgONwYHCfooNDliCjzJ6Xa6guLeC6u16QE3sDpZY73rsEgPe8/2EA3vW5jwAwS9NepTpq+YllW4IbavDONsRsX7cZgGYtruloCta+WSksbfXqSuulj71KteJsMGzXru7g/iVSSltTLMy+vk2Dg4NSVGMLcQaHQ2xdaMc4y9/RIbUGcgs1fTeSyOyWwWxqz6bPbGltYahc1vJffn60n92WvJqkqbcYs8dibZHrccXZUXTj0x3rPK6CmVEnz4x/T9r3COFgpdEONRyzOzhkCTLK7G19Q9y3cisv/1JUZRe94+3+tfPm6dDHKXMB+MSZs+QFldUsW+9aFcx6qz9+EQCv7JKmFnZtAGB1qzJw2zZ/7e5toiNn6kXVpr5B2mBLtUHGsuqeliC1l6OqsmW6xk6CsYxs2bu7P9QWW1Sq11SZRtNpdi5chNnVsrFM0j8Ynf1mffbCJEU1uTENOsvsycpl42Oc89Ma2WwfqPGIJOWyqYpqEm8yNrIxjZbpX9kxu4NDliCjzL61uZtPffOPmEbRjf/6uwMNeFtsctblEoU/tkE04a3Iwa/Xapnrnq3+nvPPkIaaX6/W4hll3Kfe7NCbBi2uQ7uF5ScvlmfOnC7+uPW7bTtsV1vA7OVV8g5WpXabToKxf5It47aEfPb8IvHv/UKYAfHvC2qk4aYvzOzaaGNZzfr+lomtXl1YfCIejbfIibe8QqA4myoab/eaUaLxo2nQ+e80uhBFVJF2DGsgsi/FBSukkeR6Sn97f55zlMExu4NDliCjzO4N9DG0bjlf++ZtACxtrPav/e9KYd7bLxKf3bKcZcgf/bFJFhaX+3uuXSJyVJ/46UtyokqOX16nAhU67QXwp8LOni1++LypwuyW5Tr7xH/2Olr8LRWzG+SRyuy7OwNLAQIZrO6Q/FVhcYzZtdmlQNthe4dD/r3P7HI4pHEDS0I291+QG+jfWxLy8+y62Oq8myQ+ezwan5dGi2vcj08ajY/7+gkyVRMbJd8fTGQjyZEOx+wODlmCjDJ7UWUV86+6mhuXyrSXnpC449/fI5Vzr94hM9Zf2iIR9ukqOrHsaamcK5l3gr9nUYOw8851bwJQMUfaYze/IWKSTD4meHjTSgAWzxJrYvEUua+NeO/s1QYYlauCQGjSsrSvAa9trNa37hwKKuGKSnRmu414a9ygqFiYvXswVG2nzG5nutmprpaJh1TcMeyzW6ayU2ntldxkLa52/lsqwUlvX9LrEPbZU7e45qQ5pXWihCmyMWI/kXDM7uCQJXBfdgeHLEFGzfjGuhLuunEpvdoX/otXg6KX1uceA6Ag70oA/uVRKZD5ixOkYYXNrwBw6s1/6e+p08GKNG8C4PhLRbHmzw8+BcDkEwKTf/eOdQCcNkMCfA1a5GKbTzZ3qImupbAAk9WMt0UobVqWa/vcbcFP20Bgxhdr04w1sxlRM75IynJ7BkKpNzVL4wE6Gxwb2mvN+LD6K5FnW9hgWbSoJlYum2ocVJLUW7xcNtnI5sSimvTM+nThzPaJhWN2B4csQUaZvTg/l4XTK/j4/VLy+vDv1wQXpy4A8Ntf//xbaZZpaZGSWNuUcu2pDf4W/y+/lp1eulisgD/fI62tx+noZoDdr2mrbHW0UMYGCde3DNib+nsaqoXZLYN1asmubX215NfcEwQaS7Sxxh+DrIU+xaoj3z0YYnaFLRyKp94GldlL8oPUW0KAzpegi2nSgc+0ebEUWHyEc/IAnf6QhlJNHImadOGimjHGPI8DB0sB52iFY3YHhyyByeRfQmNMC9ALtI619jBBHUfOu8KR9b5H0rvCkfO+szzPq092IaNfdgBjzHLP85Zm9KH7iSPpXeHIet8j6V3hyHvfZHBmvINDlsB92R0csgSH4st+5yF45v7iSHpXOLLe90h6Vzjy3jcBGffZHRwcDg2cGe/gkCVwX3YHhyxBxr7sxpjLjDHrjDFvGGNuz9Rz04UxZoYx5kljzBpjzGpjzK16vsYY86gxZoP+Wz3WvTIFY0yuMeZlY8wjejzbGPO8fsa/MMYUHOp3tDDGVBljfmWMed0Ys9YYc+bh+tkaYz6l/x94zRjzP8aYosP5s00XGfmyG2Nyge8BfwEsBN5rjFmYiWePAyPAZzzPWwicAXxM3/F24HHP8+YBj+vx4YJbgdCIHO4A/sPzvLlAO/ChQ/JWyfEt4Hee5y0AliDvfdh9tsaYacAngaWe5y0CcoHrOLw/2/Tged5B/w84E/h96PjvgL/LxLMP4J0fAi4G1gENeq4BWHeo303fZTryBbkAeATpS2sF8pJ95of4XSuBTWhAOHT+sPtsgWnAVqAG6R15BLj0cP1sx/Nfpsx4+wFabNNzhyWMMY3AScDzwGTP81Tall3A5EP1XjF8E/gsYKVvaoEOz/NsV87h9BnPBlqAu9Xt+IkxppTD8LP1PG878A1gC7AT6ARe4vD9bNOGC9DFYIwpA/4XuM3zvK7wNU/+rB/yXKUx5gqg2fO8lw71u6SJPOBk4Aee552E9EdETPbD6LOtBq5G/kBNBUqByw7pS00QMvVl3w7MCB1P13OHFYwx+cgX/eee592vp3cbYxr0egPQfKjeL4SzgauMMZuBexFT/ltAlTHGti0fTp/xNmCb53nP6/GvkC//4fjZXgRs8jyvxfO8YeB+5PM+XD/btJGpL/uLwDyNaBYgAY+HM/TstGCkYfsuYK3nef8euvQwcKP+fCPiyx9SeJ73d57nTfc8rxH5LJ/wPO99wJPAu3XZYfGuAJ7n7QK2GmPm66kLgTUchp8tYr6fYYwp0f9P2Hc9LD/bcSGDgY/LgfXAm8AXDnWwIsn7nYOYkSuBV/S/yxFf+HFgA/AYUHOo3zX23ucDj+jPxwAvAG8A9wGFh/r9Qu95IrBcP98HgerD9bMF/hF4HXgN+C+g8HD+bNP9z5XLOjhkCVyAzsEhS+C+7A4OWQL3ZXdwyBK4L7uDQ5bAfdkdHLIE7svu4JAlcF92B4cswf8PgZg7tGtMQdAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe = PositionalEmbedding(100, 0)\n",
    "y = pe.forward(torch.zeros(2, 100, 100))\n",
    "plt.imshow(y[0], cmap='Blues', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a711898",
   "metadata": {
    "id": "183cb078-d69c-47bf-8fe3-a06f1e7f80e1"
   },
   "source": [
    "### Then implement the function which calculates attention, given (Q,K,V) as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e6a0031",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a721a71-98dc-41bd-a903-c0558803759a",
    "outputId": "b6b23140-a701-4f77-e151-8da04ea31644"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[4,5,6]]).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba114fec",
   "metadata": {
    "id": "a9411fb5-7b8b-424e-a4e5-c96dadf1180e"
   },
   "outputs": [],
   "source": [
    "def attention(Q, K, V, mask=None, dropout=None):\n",
    "    #Q, K, V; batch_size, h, seq_length, dk or dv\n",
    "    rt_d_k = math.sqrt(Q.size(-1))\n",
    "    scores = torch.matmul(Q, K.transpose(-1,-2)) / rt_d_k\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -math.inf)\n",
    "        \n",
    "    p_att = scores.softmax(dim=-1)\n",
    "    size = V.size()\n",
    "    if dropout is not None:\n",
    "        p_att = dropout(p_att)\n",
    "    \n",
    "    return torch.matmul(p_att, V), p_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a8904",
   "metadata": {
    "id": "00d08431-3c7f-426e-ab9c-dc0fa1eb0ff8"
   },
   "source": [
    "### Now implement the masking function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f13900a5",
   "metadata": {
    "id": "bf0b6051-c94e-4dd6-aa24-c4938feb7d69"
   },
   "outputs": [],
   "source": [
    "def masked_attention(Q, K, V):\n",
    "    print(mask)\n",
    "    return attention(Q, K, V, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12309e30",
   "metadata": {
    "id": "aea2fb2e-ea5f-418f-93f2-d1a01b76d5d4"
   },
   "source": [
    "### Put it all together to form an entire attention block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c747f3f",
   "metadata": {
    "id": "c8691388-400d-4a65-b469-d7cb883880b1"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, h = 8, mask=None):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.h = h\n",
    "        self.dk = d_model // h\n",
    "        self.dv = self.dk\n",
    "        self.attn = None\n",
    "        self.mask = mask\n",
    "        self.WQ = nn.Linear(d_model, d_model)\n",
    "        self.WK = nn.Linear(d_model, d_model)\n",
    "        self.WV = nn.Linear(d_model, d_model)\n",
    "        self.W0 = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # x; batch_size, seq_length, d_model\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        #Linearly project X into Q, K, and V\n",
    "        queries = self.WQ(x) #batch_size, seq_length, d_model\n",
    "        keys = self.WK(x)    #batch_size, seq_length, d_model\n",
    "        values = self.WV(x)  #batch_size, seq_length, d_model\n",
    "        \n",
    "        #Split Q, K, and V into multi headed\n",
    "        queries = queries.view(batch_size, -1, self.h, self.dk).transpose(1,2)\n",
    "        keys = keys.view(batch_size, -1, self.h, self.dk).transpose(1,2)\n",
    "        values = values.view(batch_size, -1, self.h, self.dv).transpose(1,2)\n",
    "        \n",
    "        #q,k,v ; batch_size, h, seq_length, (dk or dv)\n",
    "        \n",
    "        x, self.attn = attention(queries, keys, values, mask, self.dropout)\n",
    "        #x; batch_size, h, seq_length, dk\n",
    "        #self.attn; batch_size, \n",
    "        \n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.dk * self.h)\n",
    "        #x; batch_size, seq_length, model_size\n",
    "        \n",
    "        return self.W0(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b47dd2",
   "metadata": {
    "id": "03141d67-cadc-4cce-a033-ed3cc93d44ca"
   },
   "source": [
    "### Finish the whole architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71883c64",
   "metadata": {
    "id": "35e31cef-9f1a-4c22-a449-ab070cc5ce04",
    "tags": []
   },
   "source": [
    "#### Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15fd8d00",
   "metadata": {
    "id": "4bea66c8-645d-4ec1-a97e-11f8fd3af95b"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.seq = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                 nn.ReLU(), \n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(d_ff, d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0dee2af",
   "metadata": {
    "id": "5a6c0842-6839-4428-82b3-acbeb120e32c"
   },
   "outputs": [],
   "source": [
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(AddAndNorm, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "    \n",
    "    def forward(self, x, layer):\n",
    "        return self.norm(x + layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e27755f",
   "metadata": {
    "id": "582e3e7c-bfce-44dc-9072-f2099671dea7"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, hidden_layers=2048, dropout=0.1, h=8):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mha = MultiHeadedAttention(d_model, dropout, h)\n",
    "        self.ffn = FeedForwardNetwork(d_model, hidden_layers, dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        base_mask = torch.tril(torch.ones(x.size(-2), x.size(-2))).to(x.device)\n",
    "        if mask is not None:\n",
    "            base_mask = mask*base_mask\n",
    "        x = self.ln1(x + self.mha(x, base_mask))\n",
    "        x = self.ln2(x + self.ffn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0475a26",
   "metadata": {
    "id": "a91c6050-1d12-4349-8f6f-ef670fd045b5"
   },
   "source": [
    "#### Decoder Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c714e6d9",
   "metadata": {
    "id": "6791f031-2b1a-4369-9bd5-61874187170c"
   },
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, d_model, N=8, hidden_layers=2048, dropout=0.1, h=8):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.decoder_blocks = nn.ModuleList([copy.deepcopy(DecoderBlock(d_model, hidden_layers, dropout, h)) for x in range(N)])\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3748c2",
   "metadata": {
    "id": "dee69bf4-909d-4536-9dea-48b482396448"
   },
   "source": [
    "#### Decoder only transformer\n",
    "Learned Embeddings -> +Positional embeddings -> Decoder Block (*N) -> Linear -> Softmax -> Output probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24626c05",
   "metadata": {
    "id": "8af8f781-52c2-4bbc-bf8f-2d48773ace7f"
   },
   "outputs": [],
   "source": [
    "class DecoderTransformer(nn.Module):\n",
    "    def __init__(self, d_model, vocab, N=8, d_ffl=2048, dropout=0.1, h=8, max_len=5000):\n",
    "        super(DecoderTransformer, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.learned_embeddings = nn.Embedding(vocab, d_model)\n",
    "        self.positional_embedding = PositionalEmbedding(d_model, dropout=dropout, max_len=max_len)\n",
    "        self.decoder_stack = DecoderStack(d_model, N=N, hidden_layers=d_ffl, dropout=dropout, h=h)\n",
    "        self.lin = nn.Linear(d_model, vocab)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        #x; batch_size, seq_length, vocab_len\n",
    "        embedding = self.learned_embeddings(x) #batch_size, seq_length, d_model\n",
    "        pos_embedding = self.positional_embedding(embedding) #batch_size, seq_length, d_model\n",
    "        final_embedding = self.decoder_stack(pos_embedding) #batch_size, seq_length, d_model\n",
    "        logits = self.lin(final_embedding) #.softmax(dim=-1) #batch_size, seq_length, vocab_len\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17367267",
   "metadata": {
    "id": "6f75dfca-4c85-4ad9-8a3e-5db00aae0eb5"
   },
   "source": [
    "### Training on the reverse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4ed787",
   "metadata": {
    "id": "657a5b85-945d-435c-9fc4-9c29532fbb4f"
   },
   "outputs": [],
   "source": [
    "class ReverseDataset(Dataset):\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.size = 10**length # total number of possible combinations\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.randint(10, size=(self.length,), dtype=torch.long)\n",
    "        y = torch.flip(x,(-1,))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e171e8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e0ba522-b5b9-4714-877a-edb55a11db7f",
    "outputId": "dd0814b2-0123-407c-c34f-854d4f9e7ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "rd = ReverseDataset(6)\n",
    "\n",
    "batch_size = 2048\n",
    "train_loader = DataLoader(\n",
    "    rd, shuffle=True, pin_memory=True, batch_size=batch_size\n",
    ")\n",
    "device =torch.device(\"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cce4a8",
   "metadata": {
    "id": "oEYjlRJT2c7-"
   },
   "source": [
    "#### Functional optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c60bcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "7d2e5765-8363-4e46-8f88-1d8f12bf54d8",
    "outputId": "cb42c59a-5962-498d-ea60-e86ce63e6d90"
   },
   "outputs": [],
   "source": [
    "model = DecoderTransformer(\n",
    "  d_model=128, \n",
    "  vocab=10, \n",
    "  N=2,\n",
    "  d_ffl=512, \n",
    "  dropout=0.1, \n",
    "  h=4\n",
    ").to(device).train()\n",
    "\n",
    "def train(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    max_epochs = 1\n",
    "    losses = [];\n",
    "    for epoch in range(max_epochs):\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for it, (x, y) in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            loss.backward()\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "            optimizer.step()\n",
    "            pbar.set_description(f\"epoch {epoch} iter {it}: train loss {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "402ecc29-caa3-41e8-b916-4e955a625db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5a608",
   "metadata": {
    "id": "2bRzO4nu2yVW"
   },
   "source": [
    "#### Wrapper optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b87ef21",
   "metadata": {
    "id": "Stsh_1jbmOlx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTransformerWrapper():\n",
    "    def __init__(self, model, vocab):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.decoder_transformer = model.to(self.device)\n",
    "        self.losses = []\n",
    "        self.vocab = vocab\n",
    "\n",
    "    @classmethod\n",
    "    def from_parameters(cls, d_model, vocab, d_ffl=None, height=4, heads=8, dropout=0.1, max_len=5000):\n",
    "        #vocab should be a list of allowed values\n",
    "        if d_ffl is None:\n",
    "            d_ffl = d_model * 4\n",
    "        model = DecoderTransformer(\n",
    "          d_model=d_model, \n",
    "          vocab=len(vocab), \n",
    "          N=height,\n",
    "          d_ffl=d_ffl, \n",
    "          dropout=dropout, \n",
    "          h=heads,\n",
    "          max_len=max_len\n",
    "        )\n",
    "        return cls(model, vocab)\n",
    "\n",
    "    def train(self, train_loader, lr=1e-4, max_epochs=1, loss_fn=nn.CrossEntropyLoss(), test_lambda=None):\n",
    "        self.decoder_transformer.train()\n",
    "        optimizer = optim.Adam(self.decoder_transformer.parameters(), lr=lr)\n",
    "        self.losses = []\n",
    "        for epoch in range(max_epochs):\n",
    "            pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "            for it, (x, y) in pbar:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                logits = self.decoder_transformer(x)\n",
    "                loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                loss.backward()\n",
    "                self.losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                if test_lambda is None:\n",
    "                    correct = (pred == y).type(torch.float).sum().item()\n",
    "                else:\n",
    "                    correct = test_lambda(pred, y).type(torch.float).sum().item()\n",
    "                accuracy = correct / x.size(0)\n",
    "                optimizer.step()\n",
    "                pbar.set_description(f\"epoch {epoch} iter {it}: train loss {loss.item():.5f}, accuracy {accuracy*100:0.2f}%\")\n",
    "  \n",
    "    def test(self, test_loader, test_lambda=None):\n",
    "        self.decoder_transformer.eval()\n",
    "        correct = 0\n",
    "        n = 0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "            for it, (x, y) in pbar:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                n += x.size(0)\n",
    "                logits = self.decoder_transformer(x)\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                if test_lambda is None:\n",
    "                    correct += (pred == y).type(torch.float).sum().item()\n",
    "                else:\n",
    "                    correct += test_lambda(pred, y).type(torch.float).sum().item()\n",
    "                accuracy = correct / n\n",
    "                pbar.set_description(f\"iter {it}: test accuracy {accuracy*100:.2f}%\")    \n",
    "    \n",
    "    def eval(self, x):\n",
    "        self.decoder_transformer.eval()\n",
    "        x = x.to(self.device)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logits = self.decoder_transformer(x)\n",
    "        return logits\n",
    "    \n",
    "    def top_k_logits(self, logits, k):\n",
    "        v, ix = torch.topk(logits, k)\n",
    "        out = logits.clone()\n",
    "        out[out < v[:, [-1]]] = -float('Inf')\n",
    "        return out\n",
    "\n",
    "    def sample(self, x, k=1):\n",
    "        logits = self.eval(x)[0]\n",
    "        logits = self.top_k_logits(logits, k)\n",
    "        # apply softmax to convert to probabilities\n",
    "        probs = logits.softmax(dim=-1)\n",
    "        # sample from the distribution or take the most likely\n",
    "        ix = torch.multinomial(probs, num_samples=1)\n",
    "        return([self.vocab[i.item()] for i in ix])\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        self.decoder_transformer.to(device)\n",
    "\n",
    "\n",
    "if 'handler' in locals():\n",
    "    handler = DecoderTransformerWrapper(handler.decoder_transformer, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad85f51",
   "metadata": {
    "id": "Zff1BZA2oViu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "handler = DecoderTransformerWrapper.from_parameters(d_model=128,\n",
    "                                    vocab=range(10),\n",
    "                                    height=2,\n",
    "                                    d_ffl=512, \n",
    "                                    dropout=0.1, \n",
    "                                    heads=4)\n",
    "# handler.train(train_loader, test_lambda=lambda pred, y: (pred == y)[:, -3:].all(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f497076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T17:03:25.646316Z",
     "iopub.status.busy": "2022-10-17T17:03:25.645955Z",
     "iopub.status.idle": "2022-10-17T17:03:40.556363Z",
     "shell.execute_reply": "2022-10-17T17:03:40.555249Z",
     "shell.execute_reply.started": "2022-10-17T17:03:25.646285Z"
    },
    "id": "H8dKrAFQtKLF"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    rd, shuffle=True, pin_memory=True, batch_size=1024\n",
    ")\n",
    "# handler.test(test_loader, test_lambda=lambda pred, y: (pred == y)[:, -3:].all(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc6687",
   "metadata": {},
   "source": [
    "### Works of Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01dde9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T run this the text should be saved\n",
    "# url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "# import requests\n",
    "# response = requests.get(url)\n",
    "# open(\"works.txt\", \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816ed832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class PlaywriteDataset(Dataset):\n",
    "  def __init__(self, chunk_size):\n",
    "    text = open(\"works.txt\", \"r\").read()\n",
    "    self.data = re.split(r\"\\b\", text)\n",
    "    self.vocab = sorted(set(self.data))\n",
    "    self.chunk_size = chunk_size\n",
    "    self.size = len(self.data)\n",
    "    self.vocab_size = len(self.vocab)\n",
    "    self.index_to_word = {i: word for i, word in enumerate(self.vocab)}\n",
    "    self.word_to_index = {word: i for i, word in enumerate(self.vocab)}\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.size - self.chunk_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    #Copying the example I get x and y where y is one word offset from x\n",
    "    chunk = self.data[idx:idx+self.chunk_size + 1]\n",
    "    numerical_chunk = [self.word_to_index[word] for word in chunk]\n",
    "    x = torch.tensor(numerical_chunk[:-1], dtype=torch.long)\n",
    "    y = torch.tensor(numerical_chunk[1:], dtype=torch.long)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b886563",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = PlaywriteDataset(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95aaa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([34542,  9992,   113,  8237,   113,  5523,   113, 17830,   113, 24979,\n",
       "           113,  9992,   113,  3477,   113, 10995,   113, 24979,   113, 10916,\n",
       "           113,  9165,   480, 14228,   113, 10916,   113,  9165,     1, 10039,\n",
       "           113, 17830,   113, 22293,   113, 19582,   113, 31392,   113, 33037,\n",
       "           113, 24979,   113, 12315,   113, 12317,   113, 21768,   113, 31392,\n",
       "           113, 10403,   113,  9566,   113, 12244,     0, 24317,   113, 25174,\n",
       "           113, 25577,   113, 24979]),\n",
       " tensor([ 9992,   113,  8237,   113,  5523,   113, 17830,   113, 24979,   113,\n",
       "          9992,   113,  3477,   113, 10995,   113, 24979,   113, 10916,   113,\n",
       "          9165,   480, 14228,   113, 10916,   113,  9165,     1, 10039,   113,\n",
       "         17830,   113, 22293,   113, 19582,   113, 31392,   113, 33037,   113,\n",
       "         24979,   113, 12315,   113, 12317,   113, 21768,   113, 31392,   113,\n",
       "         10403,   113,  9566,   113, 12244,     0, 24317,   113, 25174,   113,\n",
       "         25577,   113, 24979,   113]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd3618f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_loader = DataLoader(\n",
    "    pd, shuffle=True, pin_memory=True, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cb6be674",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_handler = DecoderTransformerWrapper.from_parameters(d_model=512,\n",
    "                                    vocab=pd.index_to_word,\n",
    "                                    height=8,\n",
    "                                    d_ffl=2048, \n",
    "                                    dropout=0.1, \n",
    "                                    heads=8,\n",
    "                                    max_len=pd.chunk_size)\n",
    "# word_handler.train(word_loader, test_lambda=lambda pred, y: (pred == y)[:, -3:].all(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28a4f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 17956: train loss 1.60100, accuracy 21.88%:  58%|█████▊    | 17957/31058 [54:04<39:00,  5.60it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 0 iter 29175: train loss 1.05205, accuracy 40.62%:  94%|█████████▍| 29176/31058 [1:27:51<05:44,  5.46it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 0 iter 31057: train loss 0.94542, accuracy 40.00%: 100%|██████████| 31058/31058 [1:33:31<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "word_handler.train(word_loader, test_lambda=lambda pred, y: (pred == y)[b:, -3:].all(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "080284fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(word_handler.decoder_transformer.state_dict(), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "58d538cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_handler.decoder_transformer.load_state_dict(torch.load(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f037947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so gazed on now,\n",
      "Will be a tattered weed of small worth held:\n",
      "Then being asked, where all thy beauty lies,\n",
      "Where all the treasure of thy lusty days;\n",
      "To say, within \n"
     ]
    }
   ],
   "source": [
    "x, y = pd[1001]\n",
    "def pretty_print_vocab(v):\n",
    "  print(\"\".join(list(map(lambda x: pd.index_to_word[x],v.tolist()))))\n",
    "\n",
    "pretty_print_vocab(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "438926c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gazed on now,\n",
      "Will be a tattered weed of small worth held:\n",
      "Then being asked, where all thy beauty lies,\n",
      "Where all the treasure of thy lusty days;\n",
      "To say, within thine\n"
     ]
    }
   ],
   "source": [
    "pretty_print_vocab(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bec1a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_logits(logits, k):\n",
    "    v, ix = torch.topk(logits, k)\n",
    "    out = logits.clone()\n",
    "    out[out < v[:, [-1]]] = -float('Inf')\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, x, steps, temperature=1.0, sample=False, top_k=None):\n",
    "    \"\"\"\n",
    "    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in\n",
    "    the sequence, feeding the predictions back into the model each time\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    for k in range(steps):\n",
    "        x_cond = x if x.size(1) <= 64 else x[:, -64:] # crop context if needed\n",
    "        logits = model(x_cond)\n",
    "        # pluck the logits at the final step and scale by temperature\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # optionally crop probabilities to only the top k options\n",
    "        if top_k is not None:\n",
    "            logits = top_k_logits(logits, top_k)\n",
    "        # apply softmax to convert to probabilities\n",
    "        probs = logits.softmax(dim=-1)\n",
    "        # sample from the distribution or take the most likely\n",
    "        if sample:\n",
    "            ix = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
    "        # append to the sequence and continue\n",
    "        x = torch.cat((x, ix), dim=1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5fc25286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SCENE I. Rome. A street\n",
      "\n",
      "Enter a company of mutinous citizens, with staves, clubs, and other\n",
      "weapons\n",
      "\n",
      "  FIRST CITIZEN. Before we proceed any further, hear me speak.\n",
      "  ALL. Speak, speak.\n",
      "  FIRST CITIZEN. YOU are all resolv'd.\n",
      "  THIRD CITIZEN. We are ever true of him.\n",
      "  THIRD CITIZEN. And so did I; and there is no great need of danger.\n",
      "    If he were living, I would die to heaven.\n",
      "    You would not do me good on a living prince,\n",
      "    But I should live to be your father in love.\n",
      "  SILVIA. O Eglamour, thou art a gentleman-\n",
      "    Think not I flatter, for my sake so much\n",
      "    As I have ever been my father in Rome;\n",
      "    And never shall he have thy land a living child.\n",
      "    The day shall be a last, and the last night shall lie,\n",
      "    And the last hour that ever I shall see thee.\n",
      "    O, let me kiss my sovereign, and entreat me.\n",
      "  QUEEN MARGARET. Nay, stay not, but kill me too soon.\n",
      "    No longer stay longer longer to stay all the town\n",
      "    Till I have learnt thy head for this world.\n",
      "  QUEEN MARGARET. Hie thee to hell for shame and leave this\n",
      "    world,\n",
      "    Thou cacodemon; there thy kingdom is.\n",
      "  RIVERS. My Lord of Gloucester, in those busy days\n",
      "    Which here you urge in the act of men;\n",
      "    And for my name is Walter Whitmore.\n",
      "    How now! Why start'st thou? What colour is this cloak of?\n",
      "  SIMPCOX. Red, master; red as blood.\n",
      "  GLOUCESTER. Why, that's well said. What \n"
     ]
    }
   ],
   "source": [
    "context = \" SCENE \"\n",
    "x = torch.tensor([pd.word_to_index[s] for s in re.split(r\"\\b\", context)], dtype=torch.long)[None,...].to(word_handler.device)\n",
    "y = sample(word_handler.decoder_transformer, x, 500, temperature=1.0, sample=True, top_k=1)[0]\n",
    "completion = ''.join([pd.index_to_word[int(i)] for i in y])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5e9b20f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def in_vocab(word):\n",
    "  return word in word_handler.vocab.values()\n",
    "\n",
    "in_vocab(\"hark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dbe26fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \" SCENE \"\n",
    "x = torch.tensor([pd.word_to_index[s] for s in re.split(r\"\\b\", context)], dtype=torch.long)[None,...].to(word_handler.device)\n",
    "word_handler.sample(x)[-1]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a955a5d6d72dcc9422ec8add5a84d6ce2101e50b4aaf9a0a8386fcbc86cc6bec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
